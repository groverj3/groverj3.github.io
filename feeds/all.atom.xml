<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jeff Grover. Bioinformatician.</title><link href="https://groverj3.github.io/" rel="alternate"></link><link href="https://groverj3.github.io/feeds/all.atom.xml" rel="self"></link><id>https://groverj3.github.io/</id><updated>2019-07-17T00:00:00-07:00</updated><subtitle>Bioinformatician/Ph.D. Candidate&lt;br&gt;
&lt;a href="https://cals.arizona.edu/research/mosherlab/Mosher_Lab/Home.html" target="_blank"&gt;The Mosher Lab&lt;/a&gt;
@ &lt;a href="https://www.arizona.edu/" target="_blank"&gt;The University of Arizona&lt;/a&gt;</subtitle><entry><title>Efficiently Filtering While Reading Data Into R (With Python?!)</title><link href="https://groverj3.github.io/articles/2019-07-17_efficiently-filtering-while-reading-data-into-r-with-python.html" rel="alternate"></link><published>2019-07-17T00:00:00-07:00</published><updated>2019-07-17T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-07-17:/articles/2019-07-17_efficiently-filtering-while-reading-data-into-r-with-python.html</id><summary type="html">&lt;p&gt;Working with large amounts of tabular data is a daily occurance for both
bioinformaticians and data scientists. There's a lot the two groups can learn
from each other (great future post material). However, I recently ran into a
situation that I was sure had to be relatively common. Apparently it â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Working with large amounts of tabular data is a daily occurance for both
bioinformaticians and data scientists. There's a lot the two groups can learn
from each other (great future post material). However, I recently ran into a
situation that I was sure had to be relatively common. Apparently it wasn't and I
had very little luck checking for a solution in my usual genomics/bioinformatics
cirlces, as well as the data science material I had on-hand.&lt;/p&gt;
&lt;h3&gt;The Problem&lt;/h3&gt;
&lt;p&gt;I recently received output from a large BLAST search. Something on the order of
200,000 queries. Some of those queries had many thousand hits. This is because
the search was completed with minimal filtering. The idea being, it's easy to
post-filter it, but you can't get the hits back that are thrown away. Fair
enough. It was also split between 100+ files. The files were also output in
BLAST's "format 7" (run with --outfmt 7). This means it's tabular (.tsv) with
comment lines throughout. This collection of files was actually too big to load
them into R (where I do most exploratory data analysis) and then filter them. So,
I figured there had to be a way to combine loading and filtering in a
satisfactory way. Of course, you could also pre-filter it with awk or Python
line-by-line and write it out to the hard drive, but this problem interested me.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;TLDR&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;If you have to load &lt;strong&gt;AND&lt;/strong&gt; filter you should use the lesser-known
&lt;a href="http://readr.tidyverse.org"&gt;readr&lt;/a&gt; function &lt;code&gt;read_delim_chunked()&lt;/code&gt; (and its
derivatives, &lt;code&gt;read_{tsv|csv|table}_chunked()&lt;/code&gt;) or write a parser in Python and
translate the resulting object (list of lists, dictionary of lists, or Pandas
dataframe) to R with 
&lt;a href="https://rstudio.github.io/reticulate/index.html"&gt;reticulate&lt;/a&gt;. The reason behind
this is that iterating through a file and filtering line-by-line, while a
seemingly common thing to do, is horrifically slow in R as far as I can tell. I'm
happy to eat my words if other useRs can prove I'm wrong.&lt;/p&gt;
&lt;h3&gt;Attempt #1: Writing a Line-by-line Parser in R&lt;/h3&gt;
&lt;p&gt;I read all the warnings. They say that R is slow. But is this really true? I
frequently read pretty large files into R with &lt;a href="https://readr.tidyverse.org/"&gt;readr&lt;/a&gt;
or &lt;a href="https://github.com/Rdatatable/data.table/wiki"&gt;data.table&lt;/a&gt;, and they're
&lt;em&gt;wicked fast&lt;/em&gt;. What I failed to immediately realize is that these packages are
fast because they're written in C/C++ and are effectively compiled programs that
interact with R through its API.&lt;/p&gt;
&lt;p&gt;I decided I would test this on both a subset of the data, one of the smaller
files (~2.6 GB), and the first 10,000 lines. The tsv files have comment lines
denoted with '#' and 12 columns which vary between character, float, and
integers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Example data&lt;/span&gt;
&lt;span class="n"&gt;input_file&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;test_blast_fmt7.out&amp;#39;&lt;/span&gt;
&lt;span class="nf"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;head -n 10000 test_blast_fmt7.out &amp;gt; test_blast_fmt7.head10000.out&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;input_file_head&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;test_blast_fmt7.head10000.out&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;col_names&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;query&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;subject&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;identity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;align_length&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="s"&gt;&amp;#39;mismatches&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;gap_opens&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;q_start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;q_end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="s"&gt;&amp;#39;s_start&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;s_end&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;evalue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;bit_score&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I first attempted to solve this problem by writing the following function (don't
do this).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;read_filter_blast7_lbl_base&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="c1"&gt;# Initialize a line counter&lt;/span&gt;
  &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;

  &lt;span class="c1"&gt;# Open a file connection, yield one line at a time&lt;/span&gt;
  &lt;span class="n"&gt;out_list&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;conn&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;open&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nf"&gt;while &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_line&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;readLines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;warn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

    &lt;span class="c1"&gt;# Split the line at the separator to yield a list, turn into a vector&lt;/span&gt;
    &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;strsplit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Skip comment lines&lt;/span&gt;
    &lt;span class="nf"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nf"&gt;startsWith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line[1]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
      &lt;span class="c1"&gt;# Include filtering conditions here in this if statement&lt;/span&gt;
      &lt;span class="nf"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line[3]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;line[4]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;line[11]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;out_list[[i]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;
      &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="c1"&gt;# Count lines&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="nf"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# Bind the lines as a data frame, don&amp;#39;t convert strings to factors&lt;/span&gt;
  &lt;span class="n"&gt;out_df&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.data.frame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;do.call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rbind&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out_list&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;stringsAsFactors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nf"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;

  &lt;span class="c1"&gt;# Set the column classes&lt;/span&gt;
  &lt;span class="nf"&gt;for &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;header[3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;12&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;out_df[&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out_df[&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="c1"&gt;# The out_df object will include filtered data, all columns as character vectors&lt;/span&gt;
  &lt;span class="nf"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Wow! What an abomination. I'm not sure if this says more about R's unsuitability
to this kind of task or my obvious "Python-think" that's seeping in here. It's a
mess. And it's slow. I tried testing on the first 10,000 lines of one of the
files:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Benchmark 100 iterations (default) over the first 10000 lines&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_lbl_base&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;milliseconds&lt;/span&gt;
                                                                         &lt;span class="n"&gt;expr&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_lbl_base&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;    &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;338.4403&lt;/span&gt; &lt;span class="m"&gt;346.2422&lt;/span&gt; &lt;span class="m"&gt;351.0633&lt;/span&gt; &lt;span class="m"&gt;349.2319&lt;/span&gt; &lt;span class="m"&gt;352.5961&lt;/span&gt; &lt;span class="m"&gt;404.62&lt;/span&gt;   &lt;span class="m"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It works, but this doesn't scale up to a full file (it sat for ages until I
killed it), and it suffers from R's problems with growing lists in a loop leading
to copying rather than appending. There are clearly other issues too because my
attempts to pre-allocate a list or data frame of the correct size did not speed
it up. This means that I might be doing something wrong. Regardless, this is too
much work to do something so simple. I welcome others to find a pure base R
implementation that's better. It seems like there &lt;em&gt;should&lt;/em&gt; be a way to do it.&lt;/p&gt;
&lt;p&gt;However, there are better options.&lt;/p&gt;
&lt;h3&gt;Attempt #2: Using &lt;a href="https://www.rdocumentation.org/packages/sqldf/versions/0.4-11"&gt;&lt;strong&gt;sqldf&lt;/strong&gt;&lt;/a&gt; to Filter a Temporary sqlite Database&lt;/h3&gt;
&lt;p&gt;The internet led me to believe that this isn't really something people do in R.
And if you can't load it all into memory then you should use a database and query
that. It seems excessive, but the &lt;a href="https://github.com/ggrothendieck/sqldf"&gt;sqldf&lt;/a&gt;
R package can do this. It even includes a function to create the DB on the fly
while reading (&lt;code&gt;read.csv.sql()&lt;/code&gt;) I totally understand using SQL or similar to query
a DB when you have a reason to query it often and it's stored as an SQL DB. I
question the wisdom of this suggestion though for this purpose. I was able to use
it as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;read_filter_blast7_sqldf&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;temp_df&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;read.csv.sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;filter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;sed -e &amp;#39;/^#/d&amp;#39;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;sql&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;paste0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;SELECT * FROM file WHERE V3 &amp;gt;= &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="s"&gt;&amp;#39; AND V4 &amp;gt;= &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39; AND V11 &amp;lt;= &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="n"&gt;header&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;sep&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;colClasses&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;character&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;numeric&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;integer&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="nf"&gt;rep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;numeric&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nf"&gt;colnames&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;
  &lt;span class="nf"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;temp_df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One of the key limitations here is that you need to pipe through a shell command
(sed) to remove comment lines. Not the biggest deal, but having to write a sed
command does take you out of your flow in an R or jupyter notebook. Let's see
how that performs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Benchmark 100 iterations (default) over the first 10000 lines&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_sqldf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;milliseconds&lt;/span&gt;
                                                                      &lt;span class="n"&gt;expr&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_sqldf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;72.27077&lt;/span&gt; &lt;span class="m"&gt;73.30782&lt;/span&gt; &lt;span class="m"&gt;93.27967&lt;/span&gt; &lt;span class="m"&gt;79.38143&lt;/span&gt; &lt;span class="m"&gt;103.4807&lt;/span&gt; &lt;span class="m"&gt;199.8507&lt;/span&gt;   &lt;span class="m"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;What's going on here? The max is much slower than the min. This is because the
first iteration reads this into a temporary &lt;strong&gt;file&lt;/strong&gt;! This will take
even more time for a larger file, and that temporary database will be the size of
the full, unfiltered file. Usually you load each file once, and each file needs
its own temp sqlite DB. So, the max time is actually the only timing that
matters! Plus, it has the problem of filling up your /tmp directory. What happens
when I try to load the smallest whole file (2.6 GB)?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Benchmark the whole file once&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_sqldf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;
                                                            &lt;span class="n"&gt;expr&lt;/span&gt;      &lt;span class="n"&gt;min&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_sqldf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="m"&gt;165.4224&lt;/span&gt;
       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;165.4224&lt;/span&gt; &lt;span class="m"&gt;165.4224&lt;/span&gt; &lt;span class="m"&gt;165.4224&lt;/span&gt; &lt;span class="m"&gt;165.4224&lt;/span&gt; &lt;span class="m"&gt;165.4224&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's decent performance, but because it makes temporary files it will fill up
your /tmp directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ df -h
Filesystem      Size  Used Avail Use% Mounted on
dev             &lt;span class="m"&gt;7&lt;/span&gt;.8G     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;7&lt;/span&gt;.8G   &lt;span class="m"&gt;0&lt;/span&gt;% /dev
run             &lt;span class="m"&gt;7&lt;/span&gt;.8G  &lt;span class="m"&gt;1&lt;/span&gt;.4M  &lt;span class="m"&gt;7&lt;/span&gt;.8G   &lt;span class="m"&gt;1&lt;/span&gt;% /run
/dev/nvme0n1p2  423G   34G  368G   &lt;span class="m"&gt;9&lt;/span&gt;% /
tmpfs           &lt;span class="m"&gt;7&lt;/span&gt;.8G  170M  &lt;span class="m"&gt;7&lt;/span&gt;.6G   &lt;span class="m"&gt;3&lt;/span&gt;% /dev/shm
tmpfs           &lt;span class="m"&gt;7&lt;/span&gt;.8G     &lt;span class="m"&gt;0&lt;/span&gt;  &lt;span class="m"&gt;7&lt;/span&gt;.8G   &lt;span class="m"&gt;0&lt;/span&gt;% /sys/fs/cgroup
tmpfs           &lt;span class="m"&gt;7&lt;/span&gt;.8G  &lt;span class="m"&gt;6&lt;/span&gt;.9G  913M  &lt;span class="m"&gt;89&lt;/span&gt;% /tmp
/dev/nvme0n1p1  300M  348K  300M   &lt;span class="m"&gt;1&lt;/span&gt;% /boot/efi
tmpfs           &lt;span class="m"&gt;1&lt;/span&gt;.6G   32K  &lt;span class="m"&gt;1&lt;/span&gt;.6G   &lt;span class="m"&gt;1&lt;/span&gt;% /run/user/1000
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And running it on a second file fails:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Benchmark the whole file once&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_sqldf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;connection_import_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eol&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skip&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; 
  &lt;span class="n"&gt;RS_sqlite_import&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;database&lt;/span&gt; &lt;span class="n"&gt;or&lt;/span&gt; &lt;span class="n"&gt;disk&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;full&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="n"&gt;addition&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Warning&lt;/span&gt; &lt;span class="n"&gt;message&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;In&lt;/span&gt; &lt;span class="nf"&gt;.Internal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;gc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbose&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;full&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;closing&lt;/span&gt; &lt;span class="n"&gt;unused&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_blast_fmt7.out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Error&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="nf"&gt;result_create&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conn&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ptr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;statement&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt; 
  &lt;span class="n"&gt;cannot&lt;/span&gt; &lt;span class="n"&gt;rollback&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;no&lt;/span&gt; &lt;span class="n"&gt;transaction&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;active&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I then had to &lt;code&gt;sudo rm -r /tmp/Rtmp*&lt;/code&gt; because my ssd was full.&lt;/p&gt;
&lt;p&gt;On a system with tons of space it could be fine. I'm running this on my laptop
during a flight so that doesn't help. You could also specify where those
databases are made. However, the largest file I needed to work with is 30 GB and
there were several. And this exact problem happened with that on our lab's
server. (Note to self: Ask my PI to upgrade the root drive).&lt;/p&gt;
&lt;p&gt;Still not a great solution.&lt;/p&gt;
&lt;h3&gt;Attempt #3: &lt;a href="https://readr.tidyverse.org/"&gt;&lt;strong&gt;readr&lt;/strong&gt;&lt;/a&gt; &lt;code&gt;read_delim_chunked()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;This function isn't well-documented, but is the fastest option I found. It's not
quite the line-by-line implementation I thought up, but it's similar. Basically,
it will use readr and a function (user-definable) to bind together dataframes
which are read in chunks. Getting the best performance would require optimizing
the chunk size to the largest you can reasonably handle in memory. I stuck with
10,000 because I was comparing to other options.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;readr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;read_filter_blast7_readr_chunked&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="nf"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;identity&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;align_length&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;evalue&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;out_df&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;read_tsv_chunked&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;chunk_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;comment&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;#&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DataFrameCallback&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="nf"&gt;new&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Benchmarking results in some very very solid performance:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Benchmark 100 iterations (default) over the first 10000 lines&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_readr_chunked&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;milliseconds&lt;/span&gt;
                                                                              &lt;span class="n"&gt;expr&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_readr_chunked&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;28.90464&lt;/span&gt; &lt;span class="m"&gt;29.10356&lt;/span&gt; &lt;span class="m"&gt;30.87358&lt;/span&gt; &lt;span class="m"&gt;29.92421&lt;/span&gt; &lt;span class="m"&gt;31.28273&lt;/span&gt; &lt;span class="m"&gt;92.10364&lt;/span&gt;   &lt;span class="m"&gt;100&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's not too surprising, since it's basically just reading in the whole file at
once and readr is fast. So, how's it work on the full file?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Benchmark the whole file once&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_sqldf&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;
                                                                         &lt;span class="n"&gt;expr&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_readr_chunked&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;76.59867&lt;/span&gt; &lt;span class="m"&gt;76.59867&lt;/span&gt; &lt;span class="m"&gt;76.59867&lt;/span&gt; &lt;span class="m"&gt;76.59867&lt;/span&gt; &lt;span class="m"&gt;76.59867&lt;/span&gt; &lt;span class="m"&gt;76.59867&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Really good performance. You can tune it better as well, the. This is probably your best bet without getting too
weird. But let's get weird ;)&lt;/p&gt;
&lt;h3&gt;Attempt #4: Parse With Python Translate to R With &lt;a href="https://rstudio.github.io/reticulate/index.html"&gt;&lt;strong&gt;reticulate&lt;/strong&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Let's do this in Python! Sort of...&lt;/p&gt;
&lt;p&gt;Writing a function to read and filter something in a for loop is a common thing
for me in python. I usually don't use Python for exploratory analysis though and
am less familiar with Pandas &lt;em&gt;et al.&lt;/em&gt; than I am with R's ecosystem. However, I
was able to figure out that it will automatically turn a list of lists into a
dataframe, which is pretty neat. A solid win over R's functionality:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;filter_blast7&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_blast_results&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                  &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;df_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_blast_results&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;input_handle&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_handle&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startswith&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;#&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;entry&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="n"&gt;perc_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                &lt;span class="n"&gt;al_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                &lt;span class="n"&gt;evalue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;perc_id&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_perc_id&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;al_len&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_al_len&lt;/span&gt;
                        &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;evalue&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_evalue&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="n"&gt;df_list&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;entry&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;header&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This function, when tested in python returns a data frame as expected:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;filter_blast7&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
   &lt;span class="n"&gt;query&lt;/span&gt;     &lt;span class="n"&gt;subject&lt;/span&gt;    &lt;span class="n"&gt;identity&lt;/span&gt; &lt;span class="n"&gt;align_length&lt;/span&gt; &lt;span class="n"&gt;mismatches&lt;/span&gt;  &lt;span class="o"&gt;...&lt;/span&gt; &lt;span class="n"&gt;q_end&lt;/span&gt; &lt;span class="n"&gt;s_start&lt;/span&gt; &lt;span class="n"&gt;s_end&lt;/span&gt;  &lt;span class="n"&gt;evalue&lt;/span&gt; &lt;span class="n"&gt;bit_score&lt;/span&gt;
&lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="n"&gt;query_1&lt;/span&gt;  &lt;span class="n"&gt;scaffold88&lt;/span&gt;  &lt;span class="mf"&gt;100.000&lt;/span&gt;          &lt;span class="mi"&gt;869&lt;/span&gt;          &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="mi"&gt;869&lt;/span&gt;  &lt;span class="mi"&gt;733052&lt;/span&gt;  &lt;span class="mi"&gt;733920&lt;/span&gt;    &lt;span class="mf"&gt;0.0&lt;/span&gt;      &lt;span class="mi"&gt;1605&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="n"&gt;query_1&lt;/span&gt;  &lt;span class="n"&gt;scaffold88&lt;/span&gt;   &lt;span class="mf"&gt;95.732&lt;/span&gt;          &lt;span class="mi"&gt;867&lt;/span&gt;         &lt;span class="mi"&gt;34&lt;/span&gt;  &lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="mi"&gt;869&lt;/span&gt;  &lt;span class="mi"&gt;734435&lt;/span&gt;  &lt;span class="mi"&gt;735298&lt;/span&gt;    &lt;span class="mf"&gt;0.0&lt;/span&gt;      &lt;span class="mi"&gt;1393&lt;/span&gt;
&lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="n"&gt;query_1&lt;/span&gt;   &lt;span class="n"&gt;scaffold1&lt;/span&gt;  &lt;span class="mf"&gt;100.000&lt;/span&gt;          &lt;span class="mi"&gt;869&lt;/span&gt;          &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="mi"&gt;869&lt;/span&gt;    &lt;span class="mi"&gt;4053&lt;/span&gt;    &lt;span class="mi"&gt;4921&lt;/span&gt;    &lt;span class="mf"&gt;0.0&lt;/span&gt;      &lt;span class="mi"&gt;1605&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;  &lt;span class="n"&gt;query_1&lt;/span&gt;   &lt;span class="n"&gt;scaffold1&lt;/span&gt;   &lt;span class="mf"&gt;95.732&lt;/span&gt;          &lt;span class="mi"&gt;867&lt;/span&gt;         &lt;span class="mi"&gt;34&lt;/span&gt;  &lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="mi"&gt;869&lt;/span&gt;    &lt;span class="mi"&gt;5436&lt;/span&gt;    &lt;span class="mi"&gt;6299&lt;/span&gt;    &lt;span class="mf"&gt;0.0&lt;/span&gt;      &lt;span class="mi"&gt;1393&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;  &lt;span class="n"&gt;query_3&lt;/span&gt;  &lt;span class="n"&gt;scaffold88&lt;/span&gt;  &lt;span class="mf"&gt;100.000&lt;/span&gt;          &lt;span class="mi"&gt;786&lt;/span&gt;          &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="o"&gt;...&lt;/span&gt;   &lt;span class="mi"&gt;786&lt;/span&gt;  &lt;span class="mi"&gt;735004&lt;/span&gt;  &lt;span class="mi"&gt;735789&lt;/span&gt;    &lt;span class="mf"&gt;0.0&lt;/span&gt;      &lt;span class="mi"&gt;1452&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Nice, but I thought we were using R? Well, we can actually use the R package
&lt;a href="https://rstudio.github.io/reticulate/index.html"&gt;reticulate&lt;/a&gt; to run this python
code and translate its output to an R data frame. Pretty neat! You can get it
from CRAN with &lt;code&gt;install.packages('reticulate')&lt;/code&gt;. With it installed you'll want to
make sure it can find your python installation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reticulate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;py_discover_config&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;         &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;groverj3&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;.pyenv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;shims&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;libpython&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;      &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;groverj3&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;.pyenv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;versions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;3.7.2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libpython3.7m.so&lt;/span&gt;
&lt;span class="n"&gt;pythonhome&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;     &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;groverj3&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;.pyenv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;versions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;3.7.2&lt;/span&gt;&lt;span class="o"&gt;:/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;groverj3&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;.pyenv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;versions&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;3.7.2&lt;/span&gt;
&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;        &lt;span class="m"&gt;3.7.2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Mar&lt;/span&gt; &lt;span class="m"&gt;17&lt;/span&gt; &lt;span class="m"&gt;2019&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;02&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="n"&gt;[GCC&lt;/span&gt; &lt;span class="m"&gt;8.2.1&lt;/span&gt; &lt;span class="m"&gt;20181127&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;          &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;groverj3&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;.local&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python3.7&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;packages&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;
&lt;span class="n"&gt;numpy_version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;  &lt;span class="m"&gt;1.16.4&lt;/span&gt;

&lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;versions&lt;/span&gt; &lt;span class="n"&gt;found&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; 
 &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;home&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;groverj3&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;.pyenv&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;shims&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;
 &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;
 &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;python3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;py_available&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;py_available&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;initialize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Even though it found my python installation &lt;code&gt;py_available()&lt;/code&gt; returns false? I
just forced it to true. I think this is because I use
&lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; to manage my non-system python
installation. This also required making sure the python shared library is
installed (which it is not when installed with pyenv). Now, you can either
source the python parsing function from a saved .py script, or run it inline as
follows, and coerce it to an R function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;read_filter_blast7_lbl_py&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;py_run_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;import pandas as pd&lt;/span&gt;

&lt;span class="s"&gt;def filter_blast7(input_blast_results, header, min_perc_id, min_al_len,&lt;/span&gt;
&lt;span class="s"&gt;                   max_evalue):&lt;/span&gt;
&lt;span class="s"&gt;    df_list = []&lt;/span&gt;
&lt;span class="s"&gt;    with open(input_blast_results, &amp;#39;r&amp;#39;) as input_handle:&lt;/span&gt;
&lt;span class="s"&gt;        for line in input_handle:&lt;/span&gt;
&lt;span class="s"&gt;            if not line.startswith(&amp;#39;#&amp;#39;):&lt;/span&gt;
&lt;span class="s"&gt;                entry = line.strip().split()&lt;/span&gt;
&lt;span class="s"&gt;                perc_id = float(entry[2])&lt;/span&gt;
&lt;span class="s"&gt;                al_len = int(entry[3])&lt;/span&gt;
&lt;span class="s"&gt;                evalue = float(entry[10])&lt;/span&gt;
&lt;span class="s"&gt;                if (&lt;/span&gt;
&lt;span class="s"&gt;                    perc_id &amp;gt;= min_perc_id&lt;/span&gt;
&lt;span class="s"&gt;                    and al_len &amp;gt;= min_al_len&lt;/span&gt;
&lt;span class="s"&gt;                    and evalue &amp;lt;= max_evalue&lt;/span&gt;
&lt;span class="s"&gt;                ):&lt;/span&gt;
&lt;span class="s"&gt;                    df_list.append(entry)&lt;/span&gt;
&lt;span class="s"&gt;    return pd.DataFrame(df_list, columns=header)&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;filter_blast7&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Which shows up as a "python.builtin.function."&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;class&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;read_filter_blast7_lbl_py&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;[1]&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;python.builtin.function&amp;quot;&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;python.builtin.object&amp;quot;&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now, let's benchmark that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# Benchmark 100 iterations over the first 10000 lines&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_lbl_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;milliseconds&lt;/span&gt;
                                                                       &lt;span class="n"&gt;expr&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_lbl_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;60.73332&lt;/span&gt; &lt;span class="m"&gt;62.57396&lt;/span&gt; &lt;span class="m"&gt;67.58808&lt;/span&gt; &lt;span class="m"&gt;63.75887&lt;/span&gt; &lt;span class="m"&gt;69.98544&lt;/span&gt; &lt;span class="m"&gt;105.8659&lt;/span&gt;   &lt;span class="m"&gt;100&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# Benchmark the whole file once&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_lbl_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;
                                                             &lt;span class="n"&gt;expr&lt;/span&gt;      &lt;span class="n"&gt;min&lt;/span&gt;
 &lt;span class="nf"&gt;read_filter_blast7_lbl_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="m"&gt;139.1212&lt;/span&gt;
       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;139.1212&lt;/span&gt; &lt;span class="m"&gt;139.1212&lt;/span&gt; &lt;span class="m"&gt;139.1212&lt;/span&gt; &lt;span class="m"&gt;139.1212&lt;/span&gt; &lt;span class="m"&gt;139.1212&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It also returns a data frame identical to the python one:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_filter_blast7_lbl_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file_head&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;432&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1e-50&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;query&lt;/span&gt;    &lt;span class="n"&gt;subject&lt;/span&gt;    &lt;span class="n"&gt;identity&lt;/span&gt; &lt;span class="n"&gt;align_length&lt;/span&gt; &lt;span class="n"&gt;mismatches&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="n"&gt;query_1&lt;/span&gt; &lt;span class="n"&gt;scaffold88&lt;/span&gt;  &lt;span class="m"&gt;100.000&lt;/span&gt;          &lt;span class="m"&gt;869&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="n"&gt;query_1&lt;/span&gt; &lt;span class="n"&gt;scaffold88&lt;/span&gt;   &lt;span class="m"&gt;95.732&lt;/span&gt;          &lt;span class="m"&gt;867&lt;/span&gt;         &lt;span class="m"&gt;34&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="n"&gt;query_1&lt;/span&gt;  &lt;span class="n"&gt;scaffold1&lt;/span&gt;  &lt;span class="m"&gt;100.000&lt;/span&gt;          &lt;span class="m"&gt;869&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="n"&gt;query_1&lt;/span&gt;  &lt;span class="n"&gt;scaffold1&lt;/span&gt;   &lt;span class="m"&gt;95.732&lt;/span&gt;          &lt;span class="m"&gt;867&lt;/span&gt;         &lt;span class="m"&gt;34&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="n"&gt;query_3&lt;/span&gt; &lt;span class="n"&gt;scaffold88&lt;/span&gt;  &lt;span class="m"&gt;100.000&lt;/span&gt;          &lt;span class="m"&gt;786&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt; &lt;span class="n"&gt;query_3&lt;/span&gt;  &lt;span class="n"&gt;scaffold1&lt;/span&gt;  &lt;span class="m"&gt;100.000&lt;/span&gt;          &lt;span class="m"&gt;786&lt;/span&gt;          &lt;span class="m"&gt;0&lt;/span&gt;
  &lt;span class="n"&gt;gap_opens&lt;/span&gt; &lt;span class="n"&gt;q_start&lt;/span&gt; &lt;span class="n"&gt;q_end&lt;/span&gt; &lt;span class="n"&gt;s_start&lt;/span&gt;  &lt;span class="n"&gt;s_end&lt;/span&gt; &lt;span class="n"&gt;evalue&lt;/span&gt; &lt;span class="n"&gt;bit_score&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt;         &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;1&lt;/span&gt;   &lt;span class="m"&gt;869&lt;/span&gt;  &lt;span class="m"&gt;733052&lt;/span&gt; &lt;span class="m"&gt;733920&lt;/span&gt;    &lt;span class="m"&gt;0.0&lt;/span&gt;      &lt;span class="m"&gt;1605&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;         &lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="m"&gt;3&lt;/span&gt;   &lt;span class="m"&gt;869&lt;/span&gt;  &lt;span class="m"&gt;734435&lt;/span&gt; &lt;span class="m"&gt;735298&lt;/span&gt;    &lt;span class="m"&gt;0.0&lt;/span&gt;      &lt;span class="m"&gt;1393&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;         &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;1&lt;/span&gt;   &lt;span class="m"&gt;869&lt;/span&gt;    &lt;span class="m"&gt;4053&lt;/span&gt;   &lt;span class="m"&gt;4921&lt;/span&gt;    &lt;span class="m"&gt;0.0&lt;/span&gt;      &lt;span class="m"&gt;1605&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;         &lt;span class="m"&gt;1&lt;/span&gt;       &lt;span class="m"&gt;3&lt;/span&gt;   &lt;span class="m"&gt;869&lt;/span&gt;    &lt;span class="m"&gt;5436&lt;/span&gt;   &lt;span class="m"&gt;6299&lt;/span&gt;    &lt;span class="m"&gt;0.0&lt;/span&gt;      &lt;span class="m"&gt;1393&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;         &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;1&lt;/span&gt;   &lt;span class="m"&gt;786&lt;/span&gt;  &lt;span class="m"&gt;735004&lt;/span&gt; &lt;span class="m"&gt;735789&lt;/span&gt;    &lt;span class="m"&gt;0.0&lt;/span&gt;      &lt;span class="m"&gt;1452&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;         &lt;span class="m"&gt;0&lt;/span&gt;       &lt;span class="m"&gt;1&lt;/span&gt;   &lt;span class="m"&gt;786&lt;/span&gt;    &lt;span class="m"&gt;6005&lt;/span&gt;   &lt;span class="m"&gt;6790&lt;/span&gt;    &lt;span class="m"&gt;0.0&lt;/span&gt;      &lt;span class="m"&gt;1452&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's definitely not as fast as reading it chunked with readr. However, that
Python function was easy to write and performed far better than the base R way to
read and filter line-by-line. In the future, if I have something that I know how
to do in Python I may not try to translate it to R. Just run the python code with
reticulate! &lt;/p&gt;
&lt;h3&gt;Wrapping Things Up&lt;/h3&gt;
&lt;p&gt;You would think that is a commonly done thing, to filter huge datasets while
reading. Apparently, it's not common enough in R for good documentation to exist.
In the end readr wins again with &lt;code&gt;read_delim_chunked()&lt;/code&gt;. This does require some
tuning to get the best performance, but if you pick some sane chunk_size then
further opitmization is probably unnecessary and it will work fine. However, the
revelation that communicating between python and R works so well opens up a lot
of future possibilities! Some things are just better suited to one language or
another. While Python has pandas dataframes and a large ecosystem around them
none of it is as intuitive as the &lt;a href="https://www.tidyverse.org/"&gt;tidyverse&lt;/a&gt; (to
me). Something like the two winners here are ideal for situations where you have
a huge file to load, but you know that most of the file will not meet your
filtering criteria.&lt;/p&gt;
&lt;p&gt;Using Python to do general purpose programming and communicating those results to
R for statistical testing and visualization is definitely something to consider.&lt;/p&gt;
&lt;h3&gt;Addendum: What's the Overhead of Filtering While reading?&lt;/h3&gt;
&lt;p&gt;Let's check it out, first the readr method:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_tsv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;comment&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Parsed&lt;/span&gt; &lt;span class="n"&gt;with&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="n"&gt;specification&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="nf"&gt;cols&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="n"&gt;query&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_character&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;subject&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_character&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;identity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;align_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;mismatches&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;gap_opens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;q_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;q_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;s_start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;s_end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;evalue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
  &lt;span class="n"&gt;bit_score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;col_double&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;|=================================================================|&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt;% &lt;span class="m"&gt;2685&lt;/span&gt; &lt;span class="n"&gt;MB&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;
                                                       &lt;span class="n"&gt;expr&lt;/span&gt;      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;
 &lt;span class="nf"&gt;read_tsv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;comment&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;#&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="m"&gt;64.35369&lt;/span&gt; &lt;span class="m"&gt;64.35369&lt;/span&gt;
     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;64.35369&lt;/span&gt; &lt;span class="m"&gt;64.35369&lt;/span&gt; &lt;span class="m"&gt;64.35369&lt;/span&gt; &lt;span class="m"&gt;64.35369&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is compared with 76.59867 ms for filtering. That's basically no difference.
How about the reading it in with Python using Pandas read_csv:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;read_csv_py&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;py_run_string&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="s"&gt;&amp;quot;def read_blast7(input_blast_results, header):&lt;/span&gt;
&lt;span class="s"&gt;    return pd.read_csv(input_blast_results, sep=&amp;#39;\t&amp;#39;, comment=&amp;#39;#&amp;#39;)&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;read_blast7&lt;/span&gt;

&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# Benchmark the whole file once&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;microbenchmark&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read_csv_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;times&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Unit&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;seconds&lt;/span&gt;
                               &lt;span class="n"&gt;expr&lt;/span&gt;      &lt;span class="n"&gt;min&lt;/span&gt;       &lt;span class="n"&gt;lq&lt;/span&gt;     &lt;span class="n"&gt;mean&lt;/span&gt;   &lt;span class="n"&gt;median&lt;/span&gt;
 &lt;span class="nf"&gt;read_csv_py&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_names&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="m"&gt;97.45004&lt;/span&gt; &lt;span class="m"&gt;97.45004&lt;/span&gt; &lt;span class="m"&gt;97.45004&lt;/span&gt; &lt;span class="m"&gt;97.45004&lt;/span&gt;
       &lt;span class="n"&gt;uq&lt;/span&gt;      &lt;span class="n"&gt;max&lt;/span&gt; &lt;span class="n"&gt;neval&lt;/span&gt;
 &lt;span class="m"&gt;97.45004&lt;/span&gt; &lt;span class="m"&gt;97.45004&lt;/span&gt;     &lt;span class="m"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There's clearly a bit of overhead with both of these methods, but it's pretty
minor, on the order of 10-30 ms for a 2.6 gb file.&lt;/p&gt;</content><category term="bioinformatics"></category><category term="data-science"></category><category term="r"></category><category term="python"></category><category term="big-data"></category></entry><entry><title>Variations on RNAseq Workflows for DEG Analysis</title><link href="https://groverj3.github.io/articles/2019-07-09_variations-on-rnaseq-workflows-for-deg-analysis.html" rel="alternate"></link><published>2019-07-09T00:00:00-07:00</published><updated>2019-07-09T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-07-09:/articles/2019-07-09_variations-on-rnaseq-workflows-for-deg-analysis.html</id><summary type="html">&lt;p&gt;When analyzing RNAseq you're faced with many possible analysis pipelines. The
biggest decision you need to make is what the purpose of your experiment is. I
will make the assumption that &lt;em&gt;most&lt;/em&gt; of the time people want to determine which
genes are differentially expressed between two samples, genotypes, conditions,
etc â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;When analyzing RNAseq you're faced with many possible analysis pipelines. The
biggest decision you need to make is what the purpose of your experiment is. I
will make the assumption that &lt;em&gt;most&lt;/em&gt; of the time people want to determine which
genes are differentially expressed between two samples, genotypes, conditions,
etc. In DEG analyss you are interested in gene-level expression. This means you
are &lt;strong&gt;not&lt;/strong&gt; interested in differential isoforms/transcripts or alternative
splicing.The absolute most simple version of this is simply having control and
experimental samples (preferably with &amp;gt;= 3 biological replicates each). However,
this isn't as straightforward as firing up your favorite aligner and going to
town on the data. There are other considerations.&lt;/p&gt;
&lt;h3&gt;I Have a High Quality Annotated Reference Genome or Transcriptome&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;My Reference Genome is High Quality&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align reads to reference genome (STAR, HISAT2)&lt;/li&gt;
&lt;li&gt;Count reads per gene (HTSeq-count, summarizeOverlaps, featurecounts)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the standard workflow that you're probably accustomed to. Note: it is
very important to use a &lt;em&gt;modern&lt;/em&gt; splicing-aware aligner. Do not use bowtie. Both
STAR and HISAT2 are very fast compared to older aligners and are designed for
RNAseq. Their default options are generally appropriate for most simple
experimental designs. As a bonus, STAR can actually do step 2 itself, although
the output format is kind of clunky.&lt;/p&gt;
&lt;p&gt;This workflow is a good general purpose one in model organisms, and nobody will
fault you for using it there. However, there are potentially better options.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My Annotation/transcriptome is High Quality&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pseudoalignment-based abundance estimation (Salmon, Kallisto)&lt;/li&gt;
&lt;li&gt;Aggregate abundances per gene from transcripts (tximport)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This workflow may actually be better
(&lt;a href="https://f1000research.com/articles/4-1521/v2"&gt;ref&lt;/a&gt;) even if you have a
reference genome. I've always assumed that reference-genome alignment is superior
when you have a good reference, but apparently this is not necessarily the case
for the reasons detailed here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt; very fast, potentially more accurate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt; no .bam file is generated so you can't look at positional information
from your reads, no ability to discover new transcripts later from your
alignments.&lt;/p&gt;
&lt;p&gt;Either of these workflows will work fine in this situation, and the better your
genome is the closer the first will likely approximate the second. Though, I now
believe that the second workflow should be the standard if your goal is purely
DEG analysis. There are still a lot of good reasons to want a .bam file, though
nothing is stopping you from aligning your reads anyway for future-use.&lt;/p&gt;
&lt;h3&gt;My Genome/Transcriptome is Incomplete&lt;/h3&gt;
&lt;p&gt;In this case you have some deicsions to make, yet again.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Genome is Good but Annotations Are Poor&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align to reference genome (STAR, HISAT2)&lt;/li&gt;
&lt;li&gt;Assemble transcripts, genome-guided (Stringtie)&lt;/li&gt;
&lt;li&gt;Aggregate abundances per gene from transcripts (tximport)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another option here is to use a tool like
&lt;a href="https://github.com/PASApipeline/PASApipeline/wik"&gt;PASA&lt;/a&gt; to update the
existing annotations if they exist. I've run that pipeline. It's very quirky, a
pain to get running, and if you don't need genomic coordinates I'd avoid it. You
could also use Salmon/Kallisto with StringTie's transcripts, without using its
quantification, but this seems to be an unnecessary step.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Genome and Transcriptome Are Poor&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Assemble transcriptome (Trinity)&lt;/li&gt;
&lt;li&gt;Pseudoalignment-based abundance estimation (Salmon, Kallisto)&lt;/li&gt;
&lt;li&gt;Aggregate abundances per gene from transcripts (tximport)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this case you're going to want to do a thorough &lt;em&gt;de-novo&lt;/em&gt; transcriptome
assembly using something like
&lt;a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki"&gt;Trinity&lt;/a&gt;. This
transcriptome can then be used for pseudoalignment-based abundance estimation and
then DEGs can be determined after aggregation of isoform abundances. Trinity can
be quite a resource hog, so you're going to want to
&lt;a href="https://downloadmoreram.com/"&gt;get more ram&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Why Not Cufflinks/Stringtie For Transcript Assembly In Model Organisms?&lt;/h3&gt;
&lt;p&gt;First of all, don't use Cufflinks. Stringtie is essentially a more modern
Cufflinks that's
&lt;a href="https://ccb.jhu.edu/software/stringtie/index.shtml?t=faq#comp"&gt;faster and more accurate&lt;/a&gt;.
Secondly, if you're working in a well annotated genome chances are that "novel
transcripts" you find are more likely noise, or not biologically meaningful
(unless you know better for your use-case!).&lt;/p&gt;
&lt;h3&gt;Concluding Thoughts&lt;/h3&gt;
&lt;p&gt;The paper detailing that transcript abundances, when aggregated to gene level,
improve DEG analysis is particularly interesting. This makes me rethink my usual
assumption and I now believe that tools like Salmon or Kallisto should be the go
to tools for DEG analysis when you have a good transcriptome to work with.&lt;/p&gt;
&lt;p&gt;However, I still think it's worthwhile to align your reads and generate a .bam
file. There are many types of visualizations and comparisons that you simply
can't do without them. For example, calculating coverage over featutres of
interest. If you must compare expression of genes across multiple samples or from
different experiments then you'll probably want to convert your expression values
to some normalized measurement. In this case you can use FPKM or TPM, though the
consensus seems to be that TPM is the way to go these days.&lt;/p&gt;
&lt;p&gt;And, at the end of the day you know that an out-of-date collaborator is probably
going to ask you for FPKM measurements or something anyway.&lt;/p&gt;</content><category term="bioinformatics"></category><category term="thoughts"></category></entry><entry><title>Making Better Metaplots With ggplot, Part 2</title><link href="https://groverj3.github.io/articles/2019-06-28_making-better-metaplots-with-ggplot-part-2.html" rel="alternate"></link><published>2019-06-28T00:00:00-07:00</published><updated>2019-06-28T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-06-28:/articles/2019-06-28_making-better-metaplots-with-ggplot-part-2.html</id><summary type="html">&lt;p&gt;&lt;a href="/articles/2019-06-28/making-better-metaplots-with-ggplot.html"&gt;Last time&lt;/a&gt; we
prepared our data using Deeptools.&lt;/p&gt;
&lt;p&gt;Now we're going to do something kind of scandalous. R and python, living together
in peace. What is this madness? I like R's ecosystem for manipulating data and
plotting with the &lt;a href="https://www.tidyverse.org/"&gt;tidyverse&lt;/a&gt;. It still requires some
tweaking, but with a bit of â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="/articles/2019-06-28/making-better-metaplots-with-ggplot.html"&gt;Last time&lt;/a&gt; we
prepared our data using Deeptools.&lt;/p&gt;
&lt;p&gt;Now we're going to do something kind of scandalous. R and python, living together
in peace. What is this madness? I like R's ecosystem for manipulating data and
plotting with the &lt;a href="https://www.tidyverse.org/"&gt;tidyverse&lt;/a&gt;. It still requires some
tweaking, but with a bit of a time investment you can have publication-ready
vector images in only a few lines of code. It's great for genomics data as well.
Some out there may prefer &lt;a href="https://matplotlib.org/"&gt;matplotlib&lt;/a&gt; in python, and
it is powerful, but I find it kind of tedious to use without adding another
package on-top like &lt;a href="https://seaborn.pydata.org/"&gt;Seaborn&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Genomics and data science belong together just like python and R!&lt;/p&gt;
&lt;h3&gt;1. Investigate Deeptools' Metaplot Output&lt;/h3&gt;
&lt;p&gt;Your first task with any new data is just to see what it looks like. In a
terminal my initial instinct is always to call:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;head &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;filename&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But you can also just open deeptools metaplot table in your text editor of
choice. What you'll find is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;bin&lt;/span&gt; &lt;span class="nv"&gt;labels&lt;/span&gt;    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;.&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="nv"&gt;Kb&lt;/span&gt;    ...    &lt;span class="nv"&gt;start&lt;/span&gt;    ...    &lt;span class="k"&gt;end&lt;/span&gt;    ...    &lt;span class="mi"&gt;1&lt;/span&gt;.&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="nv"&gt;Kb&lt;/span&gt;
&lt;span class="nv"&gt;bins&lt;/span&gt;        &lt;span class="mi"&gt;1&lt;/span&gt;.&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;.&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;.&lt;span class="mi"&gt;0&lt;/span&gt; ...
&lt;span class="nv"&gt;sample_name&lt;/span&gt; &lt;span class="nv"&gt;genes&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt; ...
&lt;span class="nv"&gt;sample_name&lt;/span&gt; &lt;span class="nv"&gt;genes&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt; &lt;span class="nv"&gt;score&lt;/span&gt; ...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A tab delimited table of bin labels, bin numbers, and scores (data to plot) for
each of those bins. This is a rather odd format because it's horizontal, rather
than the long format that would be more convenient. We also have a label "genes"
in position 2 of the same row as the score data. The bin labels only have 4
values in the whole row. The &lt;code&gt;--upstream&lt;/code&gt;, &lt;code&gt;--startLabel&lt;/code&gt;, &lt;code&gt;--endLabel&lt;/code&gt;, and
&lt;code&gt;--downstream&lt;/code&gt; values from the &lt;code&gt;computeMatrix&lt;/code&gt; step. We can work with this but
it's a bit unwieldly.&lt;/p&gt;
&lt;h3&gt;2. Load Data Into R&lt;/h3&gt;
&lt;p&gt;Before getting started here make sure you have the tidyverse packages installed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;install.packages&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;tidyverse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are no built-in functions to read a "transposed tsv" file like this, but
with a little &lt;a href="https://stackoverflow.com/questions/17288197/reading-a-csv-file-organized-horizontally"&gt;googling&lt;/a&gt;
this turned out to not be so bad. My original thought was to read it as a
standard .tsv file with &lt;code&gt;read_tsv()&lt;/code&gt; or base &lt;code&gt;read.csv()&lt;/code&gt; and transpose with
&lt;code&gt;t()&lt;/code&gt; but these didn't like the data. This is because of the need to keep that
first row exactly as it appears, despite most of it technically being empty,
we'll need the blank labels later. So, from that stackoverflow post I was able
to edit a few things:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;read_deeptools_table&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;count.fields&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;na.rm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;readLines&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="n"&gt;.splitvar&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;var&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;strsplit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;split&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nf"&gt;length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;
    &lt;span class="nf"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;var&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;

  &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;do.call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cbind&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;lapply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;.splitvar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;paste&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;collapse&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;plot_table&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;na.omit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;read.csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\t&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="n"&gt;[&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;]&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Remove first row with &amp;quot;gene&amp;quot; label&lt;/span&gt;

  &lt;span class="nf"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Essentially, this function is finding the length of the lines, reading the lines
as character vectors, splitting the vectors by the tab character, and creating a
new table from the vectors. Reading the data with this gives us a nice dataframe.
From here on I will be using the tidyverse packages so feel free to load them
with &lt;code&gt;library('tidyverse')&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;table_test&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;read_deeptools_table&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;metaplot.tab&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;as_tibble&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# A tibble: 600 x 4&lt;/span&gt;
   &lt;span class="n"&gt;bin.labels&lt;/span&gt;  &lt;span class="n"&gt;bins&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt;            &lt;span class="n"&gt;sample_2&lt;/span&gt;
   &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fct&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;      &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;dbl&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fct&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;               &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fct&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
 &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;-1.0&lt;/span&gt;&lt;span class="n"&gt;Kb&lt;/span&gt;         &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="m"&gt;0.7382198952879583&lt;/span&gt;  &lt;span class="m"&gt;0.008900523560209424&lt;/span&gt;
 &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="m"&gt;0.9565445026178011&lt;/span&gt;  &lt;span class="m"&gt;0.007329842931937172&lt;/span&gt;
 &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="m"&gt;0.9879581151832458&lt;/span&gt;  &lt;span class="m"&gt;0.008376963350785341&lt;/span&gt;
 &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="m"&gt;0.8026178010471204&lt;/span&gt;  &lt;span class="m"&gt;0.005235602094240838&lt;/span&gt;
 &lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="m"&gt;0.7968586387434556&lt;/span&gt;  &lt;span class="m"&gt;0.0031413612565445023&lt;/span&gt;
 &lt;span class="m"&gt;6&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;6&lt;/span&gt; &lt;span class="m"&gt;0.593717277486911&lt;/span&gt;   &lt;span class="m"&gt;0.005235602094240838&lt;/span&gt;
 &lt;span class="m"&gt;7&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;7&lt;/span&gt; &lt;span class="m"&gt;0.36230366492146604&lt;/span&gt; &lt;span class="m"&gt;0.004712041884816754&lt;/span&gt;
 &lt;span class="m"&gt;8&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;8&lt;/span&gt; &lt;span class="m"&gt;0.5392670157068064&lt;/span&gt;  &lt;span class="m"&gt;0.0&lt;/span&gt;
 &lt;span class="m"&gt;9&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;             &lt;span class="m"&gt;9&lt;/span&gt; &lt;span class="m"&gt;0.9617801047120418&lt;/span&gt;  &lt;span class="m"&gt;0.0020942408376963353&lt;/span&gt;
&lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;            &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;1.403664921465969&lt;/span&gt;   &lt;span class="m"&gt;0.01099476439790576&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;3. Convert the Data to Long Format&lt;/h3&gt;
&lt;p&gt;A quirk of ggplot is that it really likes long format data. Where, instead of
separate columns for the different samples you end up with a column of "scores"
and another of "sample_id." This means that your sample ID is actually a variable
and can be plotted. This results in a new data frame which concatenates the
current sample columns into one, replicates bin.labels and bins as needed, and
creates a new column with the sample ID for each row. The easiest way to do this
is with the &lt;code&gt;gather()&lt;/code&gt; function in tidyr:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;gather&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;sample&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;score&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;bin.labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can check out what this looks like as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;bin.labels&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;   &lt;span class="n"&gt;sample&lt;/span&gt;              &lt;span class="n"&gt;score&lt;/span&gt;
&lt;span class="m"&gt;1&lt;/span&gt;     &lt;span class="m"&gt;-1.0&lt;/span&gt;&lt;span class="n"&gt;Kb&lt;/span&gt;    &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt; &lt;span class="m"&gt;0.7382198952879583&lt;/span&gt;
&lt;span class="m"&gt;2&lt;/span&gt;               &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt; &lt;span class="m"&gt;0.9565445026178011&lt;/span&gt;
&lt;span class="m"&gt;3&lt;/span&gt;               &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt; &lt;span class="m"&gt;0.9879581151832458&lt;/span&gt;
&lt;span class="m"&gt;4&lt;/span&gt;               &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt; &lt;span class="m"&gt;0.8026178010471204&lt;/span&gt;
&lt;span class="m"&gt;5&lt;/span&gt;               &lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt; &lt;span class="m"&gt;0.7968586387434556&lt;/span&gt;
&lt;span class="m"&gt;6&lt;/span&gt;               &lt;span class="m"&gt;6&lt;/span&gt; &lt;span class="n"&gt;sample_1&lt;/span&gt;  &lt;span class="m"&gt;0.593717277486911&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="nf"&gt;tail&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
     &lt;span class="n"&gt;bin.labels&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;     &lt;span class="n"&gt;sample&lt;/span&gt;                &lt;span class="n"&gt;score&lt;/span&gt;
&lt;span class="m"&gt;1195&lt;/span&gt;             &lt;span class="m"&gt;595&lt;/span&gt; &lt;span class="n"&gt;sample_2&lt;/span&gt; &lt;span class="m"&gt;0.005759162303664922&lt;/span&gt;
&lt;span class="m"&gt;1196&lt;/span&gt;             &lt;span class="m"&gt;596&lt;/span&gt; &lt;span class="n"&gt;sample_2&lt;/span&gt;                  &lt;span class="m"&gt;0.0&lt;/span&gt;
&lt;span class="m"&gt;1197&lt;/span&gt;             &lt;span class="m"&gt;597&lt;/span&gt; &lt;span class="n"&gt;sample_2&lt;/span&gt; &lt;span class="m"&gt;0.006282722513089005&lt;/span&gt;
&lt;span class="m"&gt;1198&lt;/span&gt;             &lt;span class="m"&gt;598&lt;/span&gt; &lt;span class="n"&gt;sample_2&lt;/span&gt; &lt;span class="m"&gt;0.017277486910994764&lt;/span&gt;
&lt;span class="m"&gt;1199&lt;/span&gt;             &lt;span class="m"&gt;599&lt;/span&gt; &lt;span class="n"&gt;sample_2&lt;/span&gt; &lt;span class="m"&gt;0.020942408376963352&lt;/span&gt;
&lt;span class="m"&gt;1200&lt;/span&gt;      &lt;span class="m"&gt;1.0&lt;/span&gt;&lt;span class="n"&gt;Kb&lt;/span&gt;  &lt;span class="m"&gt;600&lt;/span&gt; &lt;span class="n"&gt;sample_2&lt;/span&gt; &lt;span class="m"&gt;0.012565445026178013&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This would be annoying to work with by hand, but ggplot2 understands it just
fine.&lt;/p&gt;
&lt;h3&gt;4. Build the ggplot Command&lt;/h3&gt;
&lt;p&gt;Now that our data is in the right format it's time to get plotting! We'll start
simple, and make it more complex from there:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  &lt;span class="nf"&gt;geom_line&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  &lt;span class="nf"&gt;scale_x_continuous&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;breaks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;bin.labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will get us started with a simple line plot. The key here is that the x axis
breaks are the bin numbers, but are labeled as the bounds, start, and end of the
features. However, this also creates a major gridline at each break. Not ideal. I
have some sensible plot defaults that I use often, which I have saved to a code
snippet on my &lt;a href="https://github.com/groverj3/genomics_visualizations/blob/master/ggplot2_pub_settings.r"&gt;github&lt;/a&gt;.
I'll use these as a starting point for the theming. Another feature we may want
to add is the ability to smooth the line. This can be accomplished by using:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;geom_smooth&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;loess&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will smooth the data with
&lt;a href="https://en.wikipedia.org/wiki/Local_regression"&gt;loess&lt;/a&gt; regression. The amount of
smoothing can be configured with the &lt;code&gt;span = ...&lt;/code&gt; parameter in &lt;code&gt;geom_smooth()&lt;/code&gt;.
You'll also want to control the size of the plot when it's saved, and perhaps
stretch or shrink its aspect ratio. This can also be controlled by ggplot2 using
&lt;code&gt;ggsave()&lt;/code&gt; at the end of our plotting command. We also will want to add the
ability to specify the colors rather than just using the defaults. It's best to
use a colorblind-friendly palette when possible. Putting this all together, our
plot command becomes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;metaplot&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start_label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end_label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_axis_label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="n"&gt;out_prefix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;smooth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aspect&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                     &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="n"&gt;start_bin&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bin.labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;start_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;
  &lt;span class="n"&gt;end_bin&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;subset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bin.labels&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;end_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;

  &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="nf"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nf"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;score&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="nf"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;smooth&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nf"&gt;geom_smooth&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;loess&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;se&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nf"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nf"&gt;geom_line&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nf"&gt;scale_color_manual&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;unlist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;strsplit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;,&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;scale_x_continuous&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;breaks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;bins&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                       &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;long_table&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="n"&gt;bin.labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;geom_vline&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xintercept&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start_bin&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end_bin&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;linetype&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;dotted&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;ylab&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_axis_label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;xlab&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Position&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;theme_bw&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;22&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;theme&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;legend.title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;element_blank&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
          &lt;span class="n"&gt;legend.position&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;bottom&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="n"&gt;legend.direction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;horizontal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="n"&gt;legend.margin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;margin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
          &lt;span class="n"&gt;legend.box.margin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;margin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;-10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
          &lt;span class="n"&gt;axis.text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;element_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
          &lt;span class="n"&gt;axis.ticks.x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;element_blank&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
          &lt;span class="n"&gt;panel.grid.major.x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;element_blank&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
          &lt;span class="n"&gt;panel.grid.minor.x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nf"&gt;element_blank&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
          &lt;span class="n"&gt;aspect.ratio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;aspect&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    &lt;span class="nf"&gt;ggsave&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;paste0&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out_prefix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
           &lt;span class="n"&gt;width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
           &lt;span class="n"&gt;height&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With a few if statements we actually can plot both the smoothed and line plots on
the same coordinate system if we want. Let's test it with some data small RNA
expression data from my
&lt;a href="https://onlinelibrary.wiley.com/doi/full/10.1111/tpj.13910"&gt;2018 paper&lt;/a&gt; over a
set of genomic features:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img src="https://github.com/groverj3/genomics_visualizations/raw/master/metaplotteR.png", style="width:600px;height:429px;"&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;I think we can agree that this is an improvement. This could still be improved by
showing error when replicates are plotted, but it's pretty good for now.&lt;/p&gt;
&lt;h3&gt;Wrapping up&lt;/h3&gt;
&lt;p&gt;While this required a little patience, I think the results are worth it. Creating
clean visualizations is necessary to get your point across. I've tidied this up
a bit and pushed the full code to github. Bonus: it runs as a standalone script
and works with any number of input samples!
&lt;a href="https://github.com/groverj3/genomics_visualizations/blob/master/metaplotteR.r"&gt;Check it out!&lt;/a&gt;&lt;/p&gt;</content><category term="bioinformatics"></category><category term="data-visualization"></category></entry><entry><title>Making Better Metaplots With ggplot, Part 1</title><link href="https://groverj3.github.io/articles/2019-06-27_making-better-metaplots-with-ggplot-part-1.html" rel="alternate"></link><published>2019-06-27T00:00:00-07:00</published><updated>2019-06-27T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-06-27:/articles/2019-06-27_making-better-metaplots-with-ggplot-part-1.html</id><summary type="html">&lt;p&gt;Commonly, in bioinformatics we're in the business of determining whether
something, be it gene expression, or DNA methylation, or splicing, etc. is
different between multiple conditions. Typically this would be done by comparing
those data and using some kind of statistical test. However, with the continued
advances in sequencing technologies â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Commonly, in bioinformatics we're in the business of determining whether
something, be it gene expression, or DNA methylation, or splicing, etc. is
different between multiple conditions. Typically this would be done by comparing
those data and using some kind of statistical test. However, with the continued
advances in sequencing technologies generating greater read depth, and these
technologies becoming more available to researchers we can also look at
genome-scale data in other ways. Testing purely on count or score data does not
inform one of the positional information associated with that data.&lt;/p&gt;
&lt;p&gt;To look at the positional context associated with genomics data we have several
options. One common way is a visualization that's often referred to as a
"metaplot" or "metagene plot." These plots are similar to the TSS or "peak" plots
commonly used to visualize chip-seq or similar data. In a metaplot the entire
length of a feature is scaled such that each feature now is composed of the same
number of "bins" of data. This allows one to visualize the data associated with
these features across their entire length. There are existing software packages
that can make these plots without too much trouble such as 
&lt;a href="https://deeptools.readthedocs.io/en/stable/"&gt;Deeptools&lt;/a&gt; or the
&lt;a href="https://bioconductor.org/packages/release/bioc/html/genomation.html"&gt;Genomation&lt;/a&gt;
R library. In particular, I find Deeptools to be a great software package, and it
makes some wonderful visualizations that would be a pain to make yourself.
Genomation requires one to be very familiar with R since it isn't a standalone
program. Deeptools is easier to use but its metaplots leave something to be
desired:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img src="/figures/2019-06-27_making-better-metaplots-with-ggplot-part-1/deeptools_example_meta.png", style="width:460px;height:275px;"&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;I like the control I have over all plot elements and the professional look that
&lt;a href="https://ggplot2.tidyverse.org/"&gt;ggplot&lt;/a&gt; affords. I use it for most of my data
visualization needs. So, I figured, why not make something prettier with it?&lt;/p&gt;
&lt;h3&gt;1. Install Required Packages&lt;/h3&gt;
&lt;p&gt;This guide will use Deeptools, a Python package with a ton of functionality that
you can play around with later, and ggplot2 from the
&lt;a href="https://www.tidyverse.org/"&gt;tidyverse&lt;/a&gt;. The tidyverse is a collection of R
libraries designed by Hadley Wickham that make data science a snap. You can
install them as follows in a terminal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install --user deeptools
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Launch the R interpreter by typing &lt;code&gt;R&lt;/code&gt; and then:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;install.packages&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;tidyverse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I recommend installing them into a user-specific library by either the &lt;code&gt;--user&lt;/code&gt;
flag for pip or setting up a .Renviron file with a path to a local library. You
can learn how to do that in my
&lt;a href="/articles/2019-06-25/managing-software-on-a-multiuser-linux-system.html"&gt;previous post&lt;/a&gt;.
You're also going to need &lt;a href="https://samtools.github.io/"&gt;samtools&lt;/a&gt;. Feel free to
use the package manager of your choice if conda is more your jam.&lt;/p&gt;
&lt;h3&gt;2. Generate the Data Table With Deeptools&lt;/h3&gt;
&lt;p&gt;Now that you've got the software installed you'll need to generate per-position
"score" information. If this is expression data or similar you can use Deeptools
again. But you should be able to use other inputs to the later steps as well. If
using expression data you can use your bam file you can use Deeptools'
bamCoverage tool. First, you need to index the alignment .bam file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;samtools index &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input_bam&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input_bam&lt;/span&gt;&lt;span class="p"&gt;%.bam&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;${}&lt;/code&gt; is the syntax for using a previously declared variable in BASH and I'll use
that kind of representation throughout for places where values should be
specified.&lt;/p&gt;
&lt;p&gt;Now that you have that out of the way. Your first step is to generate a coverage
file in bigWig format. This is a binary format but contains similar data to a
&lt;a href="https://genome.ucsc.edu/goldenPath/help/bedgraph.html"&gt;bedGraph&lt;/a&gt;. You can use
the bamCoverage tool:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;bamCoverage &lt;span class="se"&gt;\&lt;/span&gt;
    -p &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;threads_to_use&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --binSize &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --normalizeUsing &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;RPKM&lt;/span&gt;&lt;span class="p"&gt;|CPM|BPM|RPGC&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --outFileFormat bigwig &lt;span class="se"&gt;\&lt;/span&gt;
    --bam &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input_bam&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --outFileName &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input_bam&lt;/span&gt;&lt;span class="p"&gt;%.bam&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.bigWig
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A &lt;code&gt;--binsize&lt;/code&gt; of 1 will just generate per-base converage. This may be slow, and
you could increase the value if you wish. There are also other ways of generating
coverage/depth such as &lt;a href="https://github.com/brentp/mosdepth"&gt;mosdepth&lt;/a&gt; (a great
tool by Brent Pedersen). This comes with Deeptools though, and is easy to get
running. The &lt;code&gt;--normalizeUsing&lt;/code&gt; option will let you normalize the coverage by
several methods, which is particularly useful for plotting multiple experiments
together at the end.&lt;/p&gt;
&lt;p&gt;Next, you'll need to generate a score matrix. In other words, a matrix of
coverages or other values of interest. This step can be done on any score data in
a bedGraph/bigWig file, even if you did not generate it with Deeptools. So, if
you're using data from a tool other than bamCoverage this is your starting point.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;computeMatrix scale-regions &lt;span class="se"&gt;\&lt;/span&gt;
    -p &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --startLabel start &lt;span class="se"&gt;\&lt;/span&gt;
    --endLabel end &lt;span class="se"&gt;\&lt;/span&gt;
    --upstream &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;base_pairs&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --downstream &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;base_pairs&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --regionBodyLength &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;scale_length&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --regionsFileName &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;regions_bed&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --scoreFileName &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input1_bigWig&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input2_bigWig&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --outFileName &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;output_matrix&lt;/span&gt;&lt;span class="p"&gt;.gz&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--startLabel&lt;/code&gt; and &lt;code&gt;--endLabel&lt;/code&gt; values can be changed as desired, but don't
forget them! The &lt;code&gt;--upstream&lt;/code&gt; and &lt;code&gt;--downstream&lt;/code&gt; values can be as desired. The
&lt;code&gt;--regionBodyLength&lt;/code&gt; is the value to which all features will be scaled. I suggest
using either the mean or median length of the features of interest. The regions
will be input as a .bed file, and the bigWig files that were generated in the
previous step will be used where indicated. Multiple files can be input,
space separated. You can specify that the matrix be gzipped by simply adding .gz
to the name of your output file. Now, the final step is to generate the plot and
also output the raw data:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plotProfile &lt;span class="se"&gt;\&lt;/span&gt;
    --startLabel start &lt;span class="se"&gt;\&lt;/span&gt;
    --endLabel end &lt;span class="se"&gt;\&lt;/span&gt;
    --averageType &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;|median&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --matrixFile &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;input_matrix&lt;/span&gt;&lt;span class="p"&gt;.gz&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --outFileName &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;metaplot&lt;/span&gt;&lt;span class="p"&gt;.svg&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    --outFileNameData &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;metaplot&lt;/span&gt;&lt;span class="p"&gt;.tab&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will generate a plot, but also output the table of per-bin values that were
plotted. I made this with it:&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img src="/figures/2019-06-27_making-better-metaplots-with-ggplot-part-1/deeptools_example_meta2.png", style="width:460px;height:275px;"&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;I could play with Deeptools further, but the options for changing its aesthetics
are more limited than I'd like. In particular, smoothing the lines requires
smoothing the underlying data in the scoreMatrix step. Which I am not a huge fan
of. Now, let's load that table into R and make something prettier in
&lt;a href="/articles/2019-06-28_making-better-metaplots-with-ggplot-part-2.html"&gt;Part 2&lt;/a&gt;.&lt;/p&gt;</content><category term="bioinformatics"></category><category term="data-visualization"></category></entry><entry><title>Managing Software on a Multiuser Linux System</title><link href="https://groverj3.github.io/articles/2019-06-25_managing-software-on-a-multiuser-linux-system.html" rel="alternate"></link><published>2019-06-25T00:00:00-07:00</published><updated>2019-06-25T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-06-25:/articles/2019-06-25_managing-software-on-a-multiuser-linux-system.html</id><summary type="html">&lt;p&gt;When I started my Ph.D. I had a good amount of experience working in a Linux
environment on my own computers. Mostly as a hobby. My advisor had bought a small
server several years previous for a post-doc's project and I was offered this
system to use for my â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;When I started my Ph.D. I had a good amount of experience working in a Linux
environment on my own computers. Mostly as a hobby. My advisor had bought a small
server several years previous for a post-doc's project and I was offered this
system to use for my day-to-day work. It doesn't set any speed records, but it
&lt;em&gt;is&lt;/em&gt; a 24 thread system with 75gb of RAM and 12TB of storage. This makes it
perfect for running analyses that I wouldn't want to do on my laptop, but need to
be tweaked repeatedly and therefore are awkward to run on the university HPC. I
also use this server for jupyter notebooks and it still handles a few users at
a time well.&lt;/p&gt;
&lt;p&gt;Since this system was starting from a blank slate I decided to implement some
simple rules for system management. When I started out I was the only user, but
since then we've added several others and this plan has held up. This is going to
be heavily biased toward running a small server for computational work that's
shared between &amp;lt; 10 users, because that's what I do.&lt;/p&gt;
&lt;p&gt;These are ordered, but feel free to ignore that. They're really more like general
tips.&lt;/p&gt;
&lt;h3&gt;0. Run a Well-Supported (Popular) Linux Server Distro&lt;/h3&gt;
&lt;p&gt;I know, I know, I know. You may have a favorite Linux distribution. It might be
&lt;a href="https://getfedora.org/"&gt;Fedora&lt;/a&gt;, or &lt;a href="https://linuxmint.com/"&gt;Mint&lt;/a&gt;, or
&lt;a href="https://manjaro.org/"&gt;Manjaro&lt;/a&gt; (that's what I've been using). You might use
&lt;a href="https://www.archlinux.org/"&gt;Arch&lt;/a&gt;, you might be a &lt;a href="https://www.gentoo.org/"&gt;masochist&lt;/a&gt;,
or you may enjoy running something with an innovative package management system
like &lt;a href="https://www.gnu.org/software/guix/"&gt;Guix&lt;/a&gt; or &lt;a href="https://nixos.org/"&gt;NixOS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Maybe you just don't know why everyone uses this *nix stuff and don't know why
you can't just bioinformatics in Excel.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img src="/images/clippy_bioinfo.png"&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;You're welcome to use something flashier, but I'd recommend sticking to Ubuntu
Server or CentOS. Fedora Server might also be a good choice. Especially with
Ubuntu potentially not shipping 32bit support in the future. For those with more
time or inclination to fiddle around, Debian would also make a good research
computing environment. The reason for this is that most software that's already
packaged will be either in .deb (Debian and derivate, including Ubuntu) or .rpm
(Redhat, Fedora, SUSE) format. Can you extract these packages and install them on
other systems? Sure. Are you going to want to do that every time you update
stuff. No.&lt;/p&gt;
&lt;p&gt;You also want to make sure that required libraries for software you may need to
compile are available without much fussing around straight from the repositories.
You'll have to do enough annoying things. Don't make this annoying.&lt;/p&gt;
&lt;h3&gt;1. Revoke Other Users' &lt;strong&gt;sudo&lt;/strong&gt; Privileges&lt;/h3&gt;
&lt;p&gt;This may seem obvious but you'd be surprised how many academic labs don't think
about this on their private server (if they have one). It's hard to overstate the
terrible time you'll have as a sysadmin if another one of your users types the
dreaded:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo rm -r /
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo rm -r /*
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's easy to forget that "." before the "/". &lt;/p&gt;
&lt;p&gt;Or, less catasrophically, that user may try installing software in a brittle way.
Meaning, you, the humble pseudo-sysadmin who's not actually getting paid for
sysadmin tasks, will have to spend time fixing it.&lt;/p&gt;
&lt;p&gt;All it takes is for you, the SUPER USER, the GOD OF THE SERVER, to run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo deluser &lt;span class="o"&gt;{&lt;/span&gt;USERNAME&lt;span class="o"&gt;}&lt;/span&gt; sudo
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Replace {USERNAME} with the user to remove.&lt;/p&gt;
&lt;h3&gt;2. Don't Blindly Install Software From Your Distro's Repos&lt;/h3&gt;
&lt;p&gt;I did just say to pick a distro with lots of stuff in the repos, right? Yes, but
particularly in scientific/research computing you really really really can't
assume these repos are anything close to up-to-date. Don't be afraid to download
the source code and compile, or even easier, there is likely a prebuilt
binary release available on the project's github.&lt;/p&gt;
&lt;p&gt;As an example, if you're running the most recent LTS version of Ubuntu (18.04)
then the version of samtools available to you is v1.7 which is a year and a half
old at the time of writing. If you have control of the system, then at least try
to install the most recent stable versions of critical software.&lt;/p&gt;
&lt;h3&gt;3. Use an Easily Followed Convention for Manual Software Installation&lt;/h3&gt;
&lt;p&gt;When you need to download software and install it manually put it somewhere easy
to remember, and easy to find for others. I put manually installed software in
/opt/software_version and symlink the binaries to /usr/local/bin/. This way,
you quickly know what you have manually installed, and what version they are just
from the directory structure. You also make everything available in the $PATH and
runnable with just the program name.&lt;/p&gt;
&lt;p&gt;The worst thing that can happen in a broken symlink if you change software
versions, and that's an easy fix with a:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo ln -s /path/to/binary /usr/local/bin
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;4. Encourage Users To Test Software in ~/bin&lt;/h3&gt;
&lt;p&gt;Create a private bin directory inside each user's home folder. This is often
pre-configured in each user's path. If not you'll need to add it to each user's
.bashrc or .profile or .bash_profile, depending on which is the preferred method
for your distro:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# set PATH so it includes user&amp;#39;s private bin if it exists&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; -d &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;/bin&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;/bin:&lt;/span&gt;&lt;span class="nv"&gt;$PATH&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let your users test and if multiple people need it, or they're running something
all the time, then you can install it system-wide in /opt.&lt;/p&gt;
&lt;h3&gt;5. Encourage Python Users to Set Up &lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Linux systems use Python under the hood a lot. Much of the system depends on
python, and your distro's package manager has already likely installed many
python packages. However, these versions are likely old and frozen at the version
number that shipped with the OS. I dislike running software that is &lt;em&gt;years&lt;/em&gt; out
of date. Python's package management with pip is kind of a mess and it doesn't
know which packages are needed by the system, and which are installed with it.
This is improving over time, but it's still not good.&lt;/p&gt;
&lt;p&gt;To avoid this, users should install the most recent stable version of Python.
Pyenv gives you a relatively easy and very lightweight way to do this. It also
allows the system packages to coexist peacefully in the root directory so it's
harder to break things. Plus, the users get the latest Python features.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv github&lt;/a&gt; has relatively easy to follow
instructions.&lt;/p&gt;
&lt;h3&gt;6. Use User-specific Language Libraries/Packages&lt;/h3&gt;
&lt;p&gt;This pops up for us with both python and R. It boils down to never, ever, using:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo pip install &lt;span class="o"&gt;{&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;or&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;R&lt;/span&gt;
&lt;span class="nf"&gt;install.packages&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;PACKAGE_NAME&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If users can't use sudo there's no danger here anyway, but using user-specific
libraries and packages keeps things consistent. It also means that, once again,
you don't have to manage something. The following will solve this for Python:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install --user &lt;span class="o"&gt;{&lt;/span&gt;PACKAGE_NAME&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This installs packages to ~/.local/lib/python{VERSION}/site-packages &lt;/p&gt;
&lt;p&gt;R requires a bit more doing. To create a user-library I recommend creating a
.Renviron in each user's home directory and adding the following to it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# .Renviron is run every time a new R session is started&lt;/span&gt;
&lt;span class="c1"&gt;# Use .Renviron to set environment variables for R&lt;/span&gt;

&lt;span class="c1"&gt;# Use the local R library&lt;/span&gt;
&lt;span class="n"&gt;R_LIBS_USER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;~/.local/lib/R/site-library&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Wrapping up&lt;/h3&gt;
&lt;p&gt;In summary, administering a small multi-user system doesn't have to be
complicated. You do want to minimize the ability for your users to break things
though. By no means is this an exhaustive guide, but it might help you out if
you're wondering where to start.&lt;/p&gt;
&lt;p&gt;Despite the proliferation of HPC systems at Universities, and cloud computing in
enterprise environments, a smaller server for your research group is still a
good investment in 2019. Submitting jobs to a queue is fine when you're not doing
iterative work, but if you want to quickly test things it gets old really quick.
Likewise, you can easily get hardware on-par with a remote VM and it's more
readily accessed.&lt;/p&gt;
&lt;p&gt;Tune in next time for something more bioinformatics-focused!&lt;/p&gt;</content><category term="sysadmin"></category></entry><entry><title>Setting up a Static Site With Pelican and GitHub Pages</title><link href="https://groverj3.github.io/articles/2019-06-15_setting-up-a-static-site-with-pelican-and-github-pages.html" rel="alternate"></link><published>2019-06-15T00:00:00-07:00</published><updated>2019-06-15T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-06-15:/articles/2019-06-15_setting-up-a-static-site-with-pelican-and-github-pages.html</id><summary type="html">&lt;p&gt;In an effort to aid in my future job searching I decided I needed a
personal/professional website. It needed to look good, contain links to my
relevant social and job-search profiles, host some examples of work from my Ph.D.
, showcase my skillset, and host my CV. GitHub pages â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;In an effort to aid in my future job searching I decided I needed a
personal/professional website. It needed to look good, contain links to my
relevant social and job-search profiles, host some examples of work from my Ph.D.
, showcase my skillset, and host my CV. GitHub pages seemed like a natural fit,
since I already share most of my work there. GitHub recommends static site
generation with Jekyll, which I've seen to be a fine way to do that, and they
have integrated tools for working with it. However, I mostly write python
day-to-day (and R) and the idea of using a ruby-based framework for this just
seemed silly to me. So, stubborn as I am, I decided to embark on a quest to use a
python-based alternative. Pelican seemed to be the most actively developed, so I
went ahead with that.&lt;/p&gt;
&lt;p&gt;The issue I ran into is that many of the guides were unnecessarily complicated, 
or didn't contain information for my particular use-case. So, I've compiled here
the steps I used to generate this site, in the hope that it will help others.&lt;/p&gt;
&lt;h3&gt;Note Before Starting&lt;/h3&gt;
&lt;p&gt;Before starting here, I would like to mention that I will not be recommending
using a virtual environment. Why? This is overkill for a simple static site/blog
and adds unnecessary complication to a process that doesn't need to be hard at
all. These sorts of instructions are useful for more advanced deployments, and if
you need them then you probably don't need a guide as simplified as this anyway.&lt;/p&gt;
&lt;p&gt;Personally, I &lt;strong&gt;do&lt;/strong&gt; use &lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt; to manage python
installations on my home and work computers, and well as our lab server. It makes
my life much easier. But it is not &lt;strong&gt;required&lt;/strong&gt; so I won't be going over it here.&lt;/p&gt;
&lt;p&gt;I still recommend installing python packages at the user level though. Mostly a
*nix/macOS thing, I'm pretty sure Windows peeps can ignore this. This will be
explained where relevant.&lt;/p&gt;
&lt;p&gt;This guide will be GNU/Linux centric and I'm not apologizing for it :)&lt;/p&gt;
&lt;p&gt;Don't use Python 2.x, it's 2019. I'm writing these with Ubuntu and derivatives in
mind, so I will specify python3 throughout, since I believe &lt;code&gt;python&lt;/code&gt; still points
to 2.7.&lt;/p&gt;
&lt;h3&gt;Step-by-step Instructions Start Here:&lt;/h3&gt;
&lt;p&gt;Like I said above, there are existing guides for this. However, most of them
recommend installing what amounts to extreme overkill for simple GitHub pages.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Have Python and PIP Installed&lt;/p&gt;
&lt;p&gt;If you're on Linux then congrats, you've already got it. If not, consult the
docs at &lt;a href="https://www.python.org/"&gt;python.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;However, you may not have pip, the python package manager. For that check by
running:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;which pip3&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If it doesn't point to an executable then you'll need to run (Ubuntu-based):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt install python3-pip&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For other distros/package managers or macOS with homebrew consult the docs to
get the specific commands. These will likely require superuser/administrator
privileges.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install Pelican&lt;/p&gt;
&lt;p&gt;On any *nix or macOS machine the following should do the trick in  or
other terminal:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pip3 install --user pelican ghp-import Markdown typogrify&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;--user&lt;/code&gt; flag installs Pelican to your home directory and doesn't require
super-user/administrator privileges and &lt;code&gt;ghp-import&lt;/code&gt; will allow you to push
directly to github.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a New GitHub Repo and Clone&lt;/p&gt;
&lt;p&gt;It's perfectly fine to use the web interface to create a new repo, so go to
your github homepage and create a new repository with the name:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{username}.github.io&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is important, and will allow you to access your site at
{username}.github.io rather than needing extra bits on the end of your github
url. Initializing with a README and LICENSE is up to you! May I recommend the
MIT license for simplifcity and FOSSness?&lt;/p&gt;
&lt;p&gt;Go to your desired dev folder on your machine, I keep all github projects in
"~/Github/{project_name}", and clone:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cd {project_folder} &amp;amp;&amp;amp; git clone {repo.git}&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run Pelican Quickstart in Your Repo Directory&lt;/p&gt;
&lt;p&gt;Pelican comes with a handy quickstart script. Though, it's not terribly-well
documented. My settings were as follows. Only non-defaults listed (for 
defaults just push enter):&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pelican quick-start&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do you want to specify a URL prefix? Y (Followed by: 
{https://{username}.github.io})&lt;br&gt; 
What is your time zone? {insert local timezone here}&lt;br&gt;
Do you want to upload your website using GitHub Pages? Y&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This will create the skeleton of your page, and allow you start adding
content! Other things can be changed later in your config files.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a First Post&lt;/p&gt;
&lt;p&gt;By default, things created in your root level directory are turned into blog
posts. Don't ask me why this is the default, I don't like it. However, this
can be changed/hacked around later. For now create a file called &lt;code&gt;test.md&lt;/code&gt;.
Add the following to it:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Title: This is a Blog Post!&lt;br&gt;
Date: 2019-06-15&lt;br&gt;
Category: Article&lt;/p&gt;
&lt;p&gt;Hello World!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate Your Site&lt;/p&gt;
&lt;p&gt;There are several ways to do this, this is the simplest:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;make devserver&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This command starts a dev server, which automatically updates the generated
content in real-time. So you can edit and preview simultaneously. Point your
web browser of choice to &lt;code&gt;localhost:8000&lt;/code&gt; and take a look!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add a Static Page&lt;/p&gt;
&lt;p&gt;By default, things in the root directory are blog posts (configurable), but
you'll probably want some static pages that are always linked to and don't
contain blog content. For that, without stopping the devserver, create a
new folder inside the "content" subdirectory called "pages":&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mkdir ./content/pages&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Create a new markdown document in there called "about.md":&lt;/p&gt;
&lt;p&gt;&lt;code&gt;touch ./content/pages/about.md&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Fill this with the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Title: About&lt;br&gt;
Date: 2019-06-14&lt;/p&gt;
&lt;p&gt;Hello world! This is a test, using Pelican to create a github pages site.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Preview Your New Pages&lt;/p&gt;
&lt;p&gt;Go back to your browser, which should have been running the whole time, and
refresh on &lt;code&gt;localhost:8000&lt;/code&gt;. You should now see options to go to a new page
called "about." That's it! Easy peasy!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generate Your Content and Push&lt;/p&gt;
&lt;p&gt;Kill the devserver with ctrl + c. Run the following in your root directory:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;make html&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This is probably unnecessary, but in case the devserver wasn't working
correctly, then this ensures you will have no issues.&lt;/p&gt;
&lt;p&gt;Next, run the following to push to github:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;make github&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will ask for your github username and password, then pushes to your
repo.&lt;/p&gt;
&lt;p&gt;Now direct your browser to:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;https://{username}.github.io&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You site should be visible now!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Push Your Source Code to a New Branch&lt;/p&gt;
&lt;p&gt;This method of pushing creates a problem from a dev standpoint. It will write
over all content in your repo every time. Plus, it only writes the rendered
site there. If you want to work on things off this same machine, you're going
to want to push the source code. Fortunately, there's an easy workaround for
this.&lt;/p&gt;
&lt;p&gt;Go to the GitHub web interface and create a new branch called "source". This
will copy all current content to it, which is just the rendered page. Now,
back in your development folder, copy all content from your repo's folder
elsewhere (non-hidden stuff only). Then, open a terminal and type:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout source&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This switches you to the source branch. It also replaces the contents with
the rendered content-only.&lt;/p&gt;
&lt;p&gt;Delete the contents again and replace with your copy of the source code.
Now enter:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git add . &amp;amp;&amp;amp; git commit -m "Pushed source" &amp;amp;&amp;amp; git push -f origin source&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This will force a push to the source branch. Technically you don't need the
"origin source" since you've checked it out, but for extra safety since we're
already doing something that is frowned on. This will totally overwrite your
site's content with the source code used to generate it. But only on that
branch. Now you can push using the &lt;code&gt;make github&lt;/code&gt; command, which defaults to
the master branch, when you want to publish, and push with &lt;code&gt;git push origin
source&lt;/code&gt; when you want to update the source code.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Final Thoughts&lt;/h3&gt;
&lt;p&gt;You're now done! And you can switch between branches to see the source and output
from Pelican's rendering. I'll make another post later to detail some more
configuration details. Until then, the &lt;a href="https://docs.getpelican.com"&gt;docs&lt;/a&gt; are a
wonderful resource.&lt;/p&gt;</content><category term="tutorial"></category><category term="pelican"></category></entry></feed>