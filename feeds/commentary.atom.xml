<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Jeff Grover. Bioinformatician. - commentary</title><link href="https://groverj3.github.io/" rel="alternate"></link><link href="https://groverj3.github.io/feeds/commentary.atom.xml" rel="self"></link><id>https://groverj3.github.io/</id><updated>2019-08-22T00:00:00-07:00</updated><subtitle>Bioinformatician/Ph.D. Candidate&lt;br&gt;
&lt;a href="https://cals.arizona.edu/research/mosherlab/Mosher_Lab/Home.html" target="_blank"&gt;The Mosher Lab&lt;/a&gt;
@ &lt;a href="https://www.arizona.edu/" target="_blank"&gt;The University of Arizona&lt;/a&gt;</subtitle><entry><title>Just Write Your Own Python Parsers for .fastq Files</title><link href="https://groverj3.github.io/articles/2019-08-22_just-write-your-own-python-parsers-for-fastq-files.html" rel="alternate"></link><published>2019-08-22T00:00:00-07:00</published><updated>2019-08-22T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-08-22:/articles/2019-08-22_just-write-your-own-python-parsers-for-fastq-files.html</id><summary type="html">&lt;p&gt;In contrast to the &lt;a href="https://en.wikipedia.org/wiki/Zen_of_Python"&gt;zen of python&lt;/a&gt;
there are actually many ways to handle sequence data in Python. There are several
packages on &lt;a href="https://pypi.org"&gt;PyPI&lt;/a&gt; that provide parsers for sequence formats
like .fastq and .fasta. I've never bothered with these, including the oft-used
&lt;a href="https://biopython.org"&gt;Biopython&lt;/a&gt;. I vaguely remembered Biopython being slower
than …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In contrast to the &lt;a href="https://en.wikipedia.org/wiki/Zen_of_Python"&gt;zen of python&lt;/a&gt;
there are actually many ways to handle sequence data in Python. There are several
packages on &lt;a href="https://pypi.org"&gt;PyPI&lt;/a&gt; that provide parsers for sequence formats
like .fastq and .fasta. I've never bothered with these, including the oft-used
&lt;a href="https://biopython.org"&gt;Biopython&lt;/a&gt;. I vaguely remembered Biopython being slower
than any parser I'd written myself early-on in learning bioinformatics, and it
not actually being simpler to implement. However, I'd never looked at this in
detail. Additionally, I'd recently run across a few posts on
&lt;a href="https://www.biostars.org/"&gt;biostars&lt;/a&gt; where users were deriding people for asking 
"What is the most efficient way to parse a huge .fastq file" for something
similar.&lt;/p&gt;
&lt;p&gt;First of all, don't discourage people who are trying to learn. Secondly, this is
a good question! As scientists, we should know that just because data exists
doesn't meant it's good. Likewise, just because software exists doesn't mean it's
the best tool for any given job. Plus, writing simple parsers for common formats
is a good way to practice file processing for when you eventually need to do
something hard and no ready-made parser exists in a package.&lt;/p&gt;
&lt;p&gt;Rather than vaguely saying "X package is slow, do this instead" I thought it'd be
best to actually benchmark some different .fastq parser options.&lt;/p&gt;
&lt;h3&gt;The Contenders&lt;/h3&gt;
&lt;p&gt;There are several packages that include parsers for biological sequence data.
These include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://biopython.org"&gt;Biopython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://htseq.readthedocs.io"&gt;HTSeq&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scikit-bio.org/"&gt;scikit-bio&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'm familiar with Biopython from the recommendations that abound in the community
for exactly this task, and HTSeq mostly for &lt;code&gt;HTSeq-count&lt;/code&gt;. Scikit-bio seems to be
newer and under current development, so results from testing that are subject to
change. Just in case someone looks at this yers after it's written and wonders
why I got the performance that I did.&lt;/p&gt;
&lt;p&gt;When it comes to dealing with .fastq files I checked through my library of Python
scripts and came across two patterns that I'll also test compared to these
packages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reading line-by-line, using a counter to yield records&lt;/li&gt;
&lt;li&gt;Reading line-by-line, using &lt;code&gt;zip_longest()&lt;/code&gt; from &lt;code&gt;itertools&lt;/code&gt; to yield records&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Setting up the Test&lt;/h3&gt;
&lt;p&gt;I did this in a &lt;a href="https://jupyter.org"&gt;jupyter&lt;/a&gt; notebook, since that's what I use
on a day-to-day basis. Most of my interactive "data science" work is done in R,
which is mostly a consequence of at one point needing to use some R packages that
have no Python equivalents, and just rolling with that. So, actually using Python
in jupyter is a bit of a departure from the norm for me.&lt;/p&gt;
&lt;p&gt;First, you need the necessary packages. I just use pip with
&lt;a href="https://github.com/pyenv/pyenv"&gt;pyenv&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install biopython HTSeq scikit-bio
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then, started a new jupyter notebook with
&lt;a href="https://jupyterlab.readthedocs.io"&gt;jupyterlab&lt;/a&gt; (a sweet new UI for jupyter that
you should use!). Your first step is always to do your imports.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;Bio&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SeqIO&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;HTSeq&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FastqReader&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;itertools&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;zip_longest&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;skbio&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I'm only using one function from skbio, but it's just called &lt;code&gt;read()&lt;/code&gt; which is
too generic a name to just import that single function without causing all sorts
of annoyances and gnashing of teeth.&lt;/p&gt;
&lt;h3&gt;Define Some Functions to Test&lt;/h3&gt;
&lt;p&gt;In order to make the benchmarking easier to follow, I figured I'd define the
functions I want to bechmark in a consistent way:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Using Biopython&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_biopython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;SeqIO&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;fastq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;

&lt;span class="c1"&gt;# Using HTSeq&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_htseq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;FastqReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;

&lt;span class="c1"&gt;# HTSeq raw&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_htseq_raw&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;FastqReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;raw_iterator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;

&lt;span class="c1"&gt;# Skbio&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_skbio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;skbio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;io&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;fastq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;

&lt;span class="c1"&gt;# Line by line with counter&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_lbl_counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;input_handle&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_handle&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rstrip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;
                &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
                &lt;span class="n"&gt;fq_record&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="c1"&gt;# Line by line with zip_longest&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_fastq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;input_handle&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;fastq_iterator&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rstrip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_handle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;fastq_iterator&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here I intended to use two different methods from HTSeq, one which just returns
bare tuples rather than objects with other kinds of validation based on the
definition of the format. However, neither HTSeq method worked. Instead, giving a
&lt;code&gt;StopIteration&lt;/code&gt; error when it reached the end of a file. Trying to catch that
with a &lt;code&gt;try:&lt;/code&gt; &lt;code&gt;except:&lt;/code&gt; block didn't seem to work? It did parse until it reached
the end of a file though. I think this is a bug, and I may raise it with the
HTSeq people. So it is, regrettably, not included in my benchmarking results.
Also, in both custom parsers, &lt;code&gt;str.rstrip()&lt;/code&gt; was marginally faster than
&lt;code&gt;str.strip()&lt;/code&gt; so I went with that instead.&lt;/p&gt;
&lt;h3&gt;Run Some Benchmarks&lt;/h3&gt;
&lt;p&gt;I decided I would try each of these with 1 million reads from a whole-genome
bisulfite experiment. These are the R1 mates from 75bp paired end reads:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;parse_biopython&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;JWG3_2_2_R1.head.fastq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="mf"&gt;2.86&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;56.7&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;parse_skbio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;JWG3_2_2_R1.head.fastq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="nb"&gt;min&lt;/span&gt; &lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;13.7&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;parse_lbl_counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;JWG3_2_2_R1.head.fastq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="mi"&gt;295&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;14.7&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;timeit&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;parse_zip_longest&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;JWG3_2_2_R1.head.fastq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="mi"&gt;249&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="mf"&gt;2.57&lt;/span&gt; &lt;span class="n"&gt;ms&lt;/span&gt; &lt;span class="n"&gt;per&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt; &lt;span class="err"&gt;±&lt;/span&gt; &lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;runs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;loops&lt;/span&gt; &lt;span class="n"&gt;each&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;%timeit&lt;/code&gt; function there is some ipython "line magic." It simplifies timing
a single line of code. The &lt;code&gt;%%timeit&lt;/code&gt; is the "cell magic" version.&lt;/p&gt;
&lt;p&gt;It seems that skbio isn't ready for primetime just yet. The real question then
is, would biopython suffice for day-to-day work? Perhaps yes, ~1M lines in &amp;lt; 3s
(349650.35 lines per second) is a timescale that people might be willing to work
with. Keep in mind this is on my personal laptop, so it's hardly a compute
cluster. In contrast, the very simple line counter-based parser that I wrote as a
master's student back in 2013 as a python-learning exercise is nearly 10x faster!
There is also an improvement in speed for using &lt;code&gt;zip_longest()&lt;/code&gt; from &lt;code&gt;itertools&lt;/code&gt;
(a trick I'm pretty sure I saw in a post from Brent Pedersen on stackoverflow).&lt;/p&gt;
&lt;h3&gt;Visualize&lt;/h3&gt;
&lt;p&gt;I'm usually a ggplot2 useR for visualizations, but I'm already in python here so
let's use this as an excuse to try the great python plotting library
&lt;a href="https://altair-viz.github.io/"&gt;altair&lt;/a&gt;. It's declarative, like ggplot2, and you
build your plot by "mapping" your "variables" (columns) to "encodings" (analogous
to "aesthetics" in ggplot2). I ran several other benchmarks and turned them into
a &lt;a href="https://pandas.pydata.org/"&gt;pandas&lt;/a&gt; data frame. First you'll need to do some
imports:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;altair&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;alt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then make the data frame&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Create a dataframe Pandas style&lt;/span&gt;

&lt;span class="n"&gt;timing_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Method&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;biopython&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;skbio&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;lbl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;zip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                            &lt;span class="s1"&gt;&amp;#39;Reads&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tile&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                            &lt;span class="s1"&gt;&amp;#39;Time (s)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;670&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;4.4&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;40.49&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;418&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;2.86&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                         &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;14.2&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;132&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;1.32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;13.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                         &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;181&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;442&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;3.92&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;40.5&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;295&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                         &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;70.2&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;352&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1e6&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;3.19&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;32.5&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;249&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)]})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Since each record is 4 lines, converting lines to # of reads requires dividing by
four. Likewise, the benchmarking results are in various time units, so I've
converted all of them to seconds. Not particular efficiently, but for this simple
example it's fine.&lt;/p&gt;
&lt;p&gt;Now we can visualize with Altair. It has a very nice syntax inspired by ggplot2's
"grammar of graphics." It's based on
&lt;a href="https://vega.github.io/vega-lite/"&gt;vega-lite&lt;/a&gt; under the hood and allows you to
easily save your plot from jupyterlab. Here's the code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Plot without skbio&lt;/span&gt;

&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Chart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timing_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mark_point&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Reads&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Time (s)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Method&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Plot on log scale&lt;/span&gt;

&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Chart&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;timing_data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mark_point&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Reads&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Scale&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;log&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
    &lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Time (s)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;alt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Scale&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;log&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;base&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
    &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Method&amp;#39;&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;center&gt;
&lt;img alt="Scatterplot" src="/figures/2019-08-22_just-write-your-own-python-parsers-for-fastq-files/benchmark.png"&gt;
&lt;img alt="Log scale scatterplot" src="/figures/2019-08-22_just-write-your-own-python-parsers-for-fastq-files/benchmark_log.png"&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Everything scales linearly, but at massively different rates. Sci-kit bio is in
another universe in terms of time, such that you can't even visualize it with the
others in a meaningful way until you log scale everything. By the log scale, you
can essentially see that biopython is an order of magnitude faster than skbio,
and either simple parser are an order of magnitude faster again. The difference
between the two simple parsers is pretty insignificant.&lt;/p&gt;
&lt;p&gt;Note: Altair is great! Not quite as full-featured as ggplot2 in R, but it's
definitely promising and something to watch for in the future. They definitely
should make it work with jupyterlab's dark theme though. Due to the transparent
plot backgrounds it requres a light theme.&lt;/p&gt;
&lt;h3&gt;To Wrap Things Up&lt;/h3&gt;
&lt;p&gt;I'm not saying you should never use biopython, I suspect its parser does some
extra validation that my simple parsers don't. It also returns objects with some
possibly useful methods. However, if you just want to read files quckly then the
simple line-by-line parsers aren't actually very complicated to write. Plus, you
don't even need to import anything unless you want a speed boost from
&lt;code&gt;itertools&lt;/code&gt;. Additionally, if you didn't need to strip newlines you'd get a boost
from not calling an &lt;code&gt;str.strip()&lt;/code&gt; method on each line.&lt;/p&gt;
&lt;p&gt;If you're ok with living dangerously, and are sure your files are formatted
correctly you can easily write something that will outperform standard
implementations with little effort when it comes to .fastq parsing.&lt;/p&gt;</content><category term="bioinformatics"></category><category term="python"></category></entry><entry><title>Suggestions for Reproducible Bioinformatic Analyses</title><link href="https://groverj3.github.io/articles/2019-08-09_suggestions-for-reproducible-bioinformatic-analyses.html" rel="alternate"></link><published>2019-08-09T00:00:00-07:00</published><updated>2019-08-09T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-08-09:/articles/2019-08-09_suggestions-for-reproducible-bioinformatic-analyses.html</id><summary type="html">&lt;p&gt;Bioinformatic analyses often require lengthy workflows or pipleines, where the
output of program A feeds into program B, and so on. These programs may also not
output their results in a format which is convenient to use in the subsequent
steps, requiring writing a conversion script, or piping its output …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Bioinformatic analyses often require lengthy workflows or pipleines, where the
output of program A feeds into program B, and so on. These programs may also not
output their results in a format which is convenient to use in the subsequent
steps, requiring writing a conversion script, or piping its output through yet
another program. This means that something as simple as running a differential
expression experiment still requires several steps. If you aren't careful this
can result in an incredibly messy filesystem. Worse, you may not remember which
programs or scripts were run on each file, and with which options. This is a huge
issue out there and likely a good reason why it's so hard to reproduce results
even when the same underlying data is used. Additionally, you'll inevitably need
to spend time doing iterative analysis. This also needs to be documented and
reproducible.&lt;/p&gt;
&lt;p&gt;In this post I'll be explaining a few methods that we can use organize this
situation before it drives you or your coworkers mad. Depending, of course, on
the level of automation and reproucibility required of the workflow.&lt;/p&gt;
&lt;h3&gt;Suggestion 1: Interactive Terminal Sessions Are For Development &lt;strong&gt;Only&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;There is most definitely a time and a place for testing things out in your
terminal. When you're learning to use a new program, needing to check the
&lt;code&gt;--help&lt;/code&gt; or &lt;code&gt;man&lt;/code&gt; pages, figuring out how to glue together programs A and B, etc.
However, in-depth analyses for publication should not be done in this manner.&lt;/p&gt;
&lt;p&gt;This is because after running your analysis you may have absolutely no record of
what was run! Of course, some (but, criticall, not all!) programs will export a
log file. However, not all do. You can quickly end up in a situation where you
have no idea which script was run on which file. So, reserve the interactive
terminal sessions for those use cases above.&lt;/p&gt;
&lt;h3&gt;Suggestion 2: Interactive Data Manipulation Should Be Performed in R or Jupyter Notebooks&lt;/h3&gt;
&lt;p&gt;Don't use Excel. I repeat, don't use Excel.&lt;/p&gt;
&lt;p&gt;Ok, Excel has its uses. However, if you're doing complex data analysis
it's very easy to get to the scale that you'll regret using Excel quickly.
Luckily the &lt;em&gt;entire&lt;/em&gt; &lt;a href="R programming language"&gt;https://www.r-project.org/&lt;/a&gt; was 
designed for this, and &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; with
&lt;a href="https://pandas.pydata.org/index.html"&gt;Pandas&lt;/a&gt; provides some similar tools. In
addition to scale, you also have no real record of what was done in an Excel
workbook. When you combine R or Python with computational notebooks you can run
code, and see the direct output of that code below it. This tracks everything
that you've run and its outputs.&lt;/p&gt;
&lt;p&gt;Even though I do most of my interactive analysis and figure-making in R, I still
prefer Jupyter Notebooks over R Notebooks. This is because they're more widely
used, and Jupyter is extensible to multiple languages. Installing the
&lt;a href="https://irkernel.github.io/"&gt;R Kernel&lt;/a&gt; is very simple.&lt;/p&gt;
&lt;h3&gt;Suggestion 3: Single-run Pipelines Should be Automated With Shell Scripts&lt;/h3&gt;
&lt;p&gt;When you write a one-off pipeline it should still be automated with a script.
This enables reproducibility. In a perfect world you'd list the version of each
piece of software in the pipeline as well. This could result in a single shell
script file, or separate ones for each step. You may not know the next step
a-priori. These shell scripts should clearly indicate the date of creation and
the script's purpose. This is a simple example for one step in a single-use
pipeline:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env bash&lt;/span&gt;

&lt;span class="c1"&gt;# Author: Jeffrey Grover&lt;/span&gt;
&lt;span class="c1"&gt;# Date: 2019-07-24&lt;/span&gt;
&lt;span class="c1"&gt;# Purpose: Extract reads over small RNA loci groups with bedtools intersect&lt;/span&gt;

&lt;span class="c1"&gt;# Use bedtools intersect and pipe to bam2fq&lt;/span&gt;

&lt;span class="nv"&gt;align_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;~/large_data/2019-06-28_aligned_reads&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; bed_file in ./srna_groups/*.bed&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;

    &lt;span class="nv"&gt;bed_filename&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;basename &lt;span class="nv"&gt;$bed_file&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;out_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;bed_filename&lt;/span&gt;&lt;span class="p"&gt;%.bed&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;_reads
    mkdir &lt;span class="s2"&gt;&amp;quot;./&lt;/span&gt;&lt;span class="nv"&gt;$out_dir&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; bamfile in &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;align_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/*.bam&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;

        &lt;span class="nv"&gt;bamfile_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;basename &lt;span class="nv"&gt;$bamfile&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;

        bedtools intersect &lt;span class="se"&gt;\&lt;/span&gt;
                -ubam &lt;span class="se"&gt;\&lt;/span&gt;
                -a &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$bamfile&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
                -b &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$srna_file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
            &lt;span class="p"&gt;|&lt;/span&gt; samtools bam2fq -n - &amp;gt; &lt;span class="s2"&gt;&amp;quot;./&lt;/span&gt;&lt;span class="nv"&gt;$out_dir&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;$bamfile_name&lt;/span&gt;&lt;span class="s2"&gt;.fq&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;done&lt;/span&gt;

    pigz -p &lt;span class="m"&gt;10&lt;/span&gt; ./&lt;span class="nv"&gt;$out_dir&lt;/span&gt;/*.fq
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I work with a lot of small RNA sequencing, and I recently needed to extract reads
from several different groups of small RNA loci I'd defined. It's relatively
simple to use &lt;code&gt;bedtools intersect&lt;/code&gt; with your interesting loci as a .bed file and
pipe that output to &lt;code&gt;samtools bam2fq&lt;/code&gt;. This isn't the kind of thing that's a
standard analysis I need to do and it's not very long. Therefore, to enable it to
be reproducible writing a quick shell script like this is the way to go. The
comment lines also carry enough information to tell someone what it does.&lt;/p&gt;
&lt;h3&gt;Suggestion 4: Long Pipelines Should Have a &lt;strong&gt;W i d e&lt;/strong&gt; Directory Structure&lt;/h3&gt;
&lt;p&gt;What does this mean? It means this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;groverj3@x1-carbon wgbs_snakemake&lt;span class="o"&gt;]&lt;/span&gt;$ ls
1_fastqc_raw                4_methyldackel_mbias    config.yaml  README.md         Snakefile
2_trim_galore               5_methyldackel_extract  input_data   reference_genome  temp_data
3_aligned_sorted_markdupes  6_mosdepth              LICENSE      scripts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and not this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wgbs_snakemake/1_fastqc_raw/2_trim_galore/3_aligned_sorted_markdupes/4_methyldackel_mbias/5_methyldackel_extract/6_mosdepth
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This makes navigating your directory structure much less of a pain. Especially
when a pipeline is several steps long.&lt;/p&gt;
&lt;h3&gt;Suggestion 5: Automate Often-run Pipelines With Workflow Managers&lt;/h3&gt;
&lt;p&gt;If there is a particular pipeline that you run frequently then consider using a
workflow manager. Options include:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://snakemake.readthedocs.io/en/stable/"&gt;snakemake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nextflow.io/"&gt;Nextflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://scipipe.org/"&gt;scipipe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/pharmbio/sciluigi"&gt;SciLuigi&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;My vote goes to Snakemake with Nextflow as a close second. These tools require
some fiddling to transfer over an existing pipeline to fit their framework, but
what you gain is reproducibility and automation. Additionally, they all utilize
threading with parallel steps better than your BASH script does. They also work
with HPC job submission frameworks (SLURM, PBS, etc.) and containers.&lt;/p&gt;
&lt;p&gt;Writing these workflows is beyond the scope of this article, but definitely worth
writing in detail about in a future one!&lt;/p&gt;
&lt;p&gt;A word of caution: it's easy to think, "Oh, I'm only going to analyze bisulfite
sequencing this one time" only to find yourself running your workflow several
times as you acquire more data. There are also some freely available workflows
already written that you can check out!&lt;/p&gt;
&lt;p&gt;(Shameless plug for &lt;a href="https://github.com/groverj3/wgbs_snakemake"&gt;mine&lt;/a&gt;)&lt;/p&gt;
&lt;h3&gt;Suggestion 6: Containerize!&lt;/h3&gt;
&lt;p&gt;Wrap-up your workflow and its required software in a container for the ultimate
write once run anywhere solution. You can make a 
&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; container with your entire workflow which can
then be used on your server, or cloud computing. However, in order to run this in
an HPC environment you'll need to run it through 
&lt;a href="https://sylabs.io/"&gt;Singularity&lt;/a&gt; instead. That's fine though! Singularity can
run Docker containers, and you'll already have one to use for cloud compute if
needed.&lt;/p&gt;
&lt;h3&gt;Wrapping up&lt;/h3&gt;
&lt;p&gt;Hopefully you've found this informative and helpful. Next time I'll be back with
more practical examples.&lt;/p&gt;</content><category term="bioinformatics"></category><category term="thoughts"></category><category term="workflows"></category></entry><entry><title>Variations on RNAseq Workflows for DEG Analysis</title><link href="https://groverj3.github.io/articles/2019-07-09_variations-on-rnaseq-workflows-for-deg-analysis.html" rel="alternate"></link><published>2019-07-09T00:00:00-07:00</published><updated>2019-07-09T00:00:00-07:00</updated><author><name>Jeffrey Grover</name></author><id>tag:groverj3.github.io,2019-07-09:/articles/2019-07-09_variations-on-rnaseq-workflows-for-deg-analysis.html</id><summary type="html">&lt;p&gt;When analyzing RNAseq you're faced with many possible analysis pipelines. The
biggest decision you need to make is what the purpose of your experiment is. I
will make the assumption that &lt;em&gt;most&lt;/em&gt; of the time people want to determine which
genes are differentially expressed between two samples, genotypes, conditions,
etc …&lt;/p&gt;</summary><content type="html">&lt;p&gt;When analyzing RNAseq you're faced with many possible analysis pipelines. The
biggest decision you need to make is what the purpose of your experiment is. I
will make the assumption that &lt;em&gt;most&lt;/em&gt; of the time people want to determine which
genes are differentially expressed between two samples, genotypes, conditions,
etc. In DEG analyss you are interested in gene-level expression. This means you
are &lt;strong&gt;not&lt;/strong&gt; interested in differential isoforms/transcripts or alternative
splicing.The absolute most simple version of this is simply having control and
experimental samples (preferably with &amp;gt;= 3 biological replicates each). However,
this isn't as straightforward as firing up your favorite aligner and going to
town on the data. There are other considerations.&lt;/p&gt;
&lt;h3&gt;I Have a High Quality Annotated Reference Genome or Transcriptome&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;My Reference Genome is High Quality&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align reads to reference genome (STAR, HISAT2)&lt;/li&gt;
&lt;li&gt;Count reads per gene (HTSeq-count, summarizeOverlaps, featurecounts)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the standard workflow that you're probably accustomed to. Note: it is
very important to use a &lt;em&gt;modern&lt;/em&gt; splicing-aware aligner. Do not use bowtie. Both
STAR and HISAT2 are very fast compared to older aligners and are designed for
RNAseq. Their default options are generally appropriate for most simple
experimental designs. As a bonus, STAR can actually do step 2 itself, although
the output format is kind of clunky.&lt;/p&gt;
&lt;p&gt;This workflow is a good general purpose one in model organisms, and nobody will
fault you for using it there. However, there are potentially better options.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My Annotation/transcriptome is High Quality&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pseudoalignment-based abundance estimation (Salmon, Kallisto)&lt;/li&gt;
&lt;li&gt;Aggregate abundances per gene from transcripts (tximport)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This workflow may actually be better
(&lt;a href="https://f1000research.com/articles/4-1521/v2"&gt;ref&lt;/a&gt;) even if you have a
reference genome. I've always assumed that reference-genome alignment is superior
when you have a good reference, but apparently this is not necessarily the case
for the reasons detailed here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt; very fast, potentially more accurate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt; no .bam file is generated so you can't look at positional information
from your reads, no ability to discover new transcripts later from your
alignments.&lt;/p&gt;
&lt;p&gt;Either of these workflows will work fine in this situation, and the better your
genome is the closer the first will likely approximate the second. Though, I now
believe that the second workflow should be the standard if your goal is purely
DEG analysis. There are still a lot of good reasons to want a .bam file, though
nothing is stopping you from aligning your reads anyway for future-use.&lt;/p&gt;
&lt;h3&gt;My Genome/Transcriptome is Incomplete&lt;/h3&gt;
&lt;p&gt;In this case you have some deicsions to make, yet again.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Genome is Good but Annotations Are Poor&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Align to reference genome (STAR, HISAT2)&lt;/li&gt;
&lt;li&gt;Assemble transcripts, genome-guided (Stringtie)&lt;/li&gt;
&lt;li&gt;Aggregate abundances per gene from transcripts (tximport)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another option here is to use a tool like
&lt;a href="https://github.com/PASApipeline/PASApipeline/wik"&gt;PASA&lt;/a&gt; to update the
existing annotations if they exist. I've run that pipeline. It's very quirky, a
pain to get running, and if you don't need genomic coordinates I'd avoid it. You
could also use Salmon/Kallisto with StringTie's transcripts, without using its
quantification, but this seems to be an unnecessary step.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Genome and Transcriptome Are Poor&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Assemble transcriptome (Trinity)&lt;/li&gt;
&lt;li&gt;Pseudoalignment-based abundance estimation (Salmon, Kallisto)&lt;/li&gt;
&lt;li&gt;Aggregate abundances per gene from transcripts (tximport)&lt;/li&gt;
&lt;li&gt;DEG Analysis (DESeq2, edgeR)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this case you're going to want to do a thorough &lt;em&gt;de-novo&lt;/em&gt; transcriptome
assembly using something like
&lt;a href="https://github.com/trinityrnaseq/trinityrnaseq/wiki"&gt;Trinity&lt;/a&gt;. This
transcriptome can then be used for pseudoalignment-based abundance estimation and
then DEGs can be determined after aggregation of isoform abundances. Trinity can
be quite a resource hog, so you're going to want to
&lt;a href="https://downloadmoreram.com/"&gt;get more ram&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Why Not Cufflinks/Stringtie For Transcript Assembly In Model Organisms?&lt;/h3&gt;
&lt;p&gt;First of all, don't use Cufflinks. Stringtie is essentially a more modern
Cufflinks that's
&lt;a href="https://ccb.jhu.edu/software/stringtie/index.shtml?t=faq#comp"&gt;faster and more accurate&lt;/a&gt;.
Secondly, if you're working in a well annotated genome chances are that "novel
transcripts" you find are more likely noise, or not biologically meaningful
(unless you know better for your use-case!).&lt;/p&gt;
&lt;h3&gt;Concluding Thoughts&lt;/h3&gt;
&lt;p&gt;The paper detailing that transcript abundances, when aggregated to gene level,
improve DEG analysis is particularly interesting. This makes me rethink my usual
assumption and I now believe that tools like Salmon or Kallisto should be the go
to tools for DEG analysis when you have a good transcriptome to work with.&lt;/p&gt;
&lt;p&gt;However, I still think it's worthwhile to align your reads and generate a .bam
file. There are many types of visualizations and comparisons that you simply
can't do without them. For example, calculating coverage over featutres of
interest. If you must compare expression of genes across multiple samples or from
different experiments then you'll probably want to convert your expression values
to some normalized measurement. In this case you can use FPKM or TPM, though the
consensus seems to be that TPM is the way to go these days.&lt;/p&gt;
&lt;p&gt;And, at the end of the day you know that an out-of-date collaborator is probably
going to ask you for FPKM measurements or something anyway.&lt;/p&gt;</content><category term="bioinformatics"></category><category term="thoughts"></category><category term="rnaseq"></category><category term="workflows"></category></entry></feed>